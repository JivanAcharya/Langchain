{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.text.TextLoader at 0x7b86975a7340>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Text loader\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader =TextLoader(\"test.txt\")\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'test.txt'}, page_content='Freemium Model: Offer basic features for free but charge for advanced analytics, detailed insights, or priority updates.\\nSubscription Model: Provide regular, ongoing value through personalized reports, alerts, or insights for users who subscribe.\\nAffiliate Marketing: Recommend products, tools, or services based on subreddit discussions and earn commissions from affiliate partnerships.\\nBusiness-to-Business (B2B): Target businesses, brands, or market researchers who are interested in understanding user sentiment and trends in the subreddit’s niche.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_doc = loader.load()\n",
    "text_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'RealTabformer.pdf', 'page': 0}, page_content='REaLTabFormer: Generating Realistic Relational\\nand Tabular Data using Transformers\\nAivin V . Solatorio1Olivier Dupriez1\\nAbstract\\nTabular data is a common form of organizing data.\\nMultiple models are available to generate syn-\\nthetic tabular datasets where observations are in-\\ndependent, but few have the ability to produce\\nrelational datasets. Modeling relational data is\\nchallenging as it requires modeling both a “par-\\nent” table and its relationships across tables. We\\nintroduce REaLTabFormer (Realistic Relational\\nand Tabular Transformer), a tabular and relational\\nsynthetic data generation model. It ﬁrst creates a\\nparent table using an autoregressive GPT-2 model,\\nthen generates the relational dataset conditioned\\non the parent table using a sequence-to-sequence\\n(Seq2Seq) model. We implement target masking\\nto prevent data copying and propose the Qδstatis-\\ntic and statistical bootstrapping to detect over-\\nﬁtting. Experiments using real-world datasets\\nshow that REaLTabFormer captures the relational\\nstructure better than a baseline model. REaLTab-\\nFormer also achieves state-of-the-art results on\\nprediction tasks, “out-of-the-box”, for large non-\\nrelational datasets without needing ﬁne-tuning.\\n1. Introduction\\nTabular data is one of the most common forms of data. Many\\ndatasets from surveys, censuses, and administrative sources\\nare provided in this form. These datasets may contain sensi-\\ntive information that cannot be shared openly (Abdelhameed\\net al., 2018). Even when statistical disclosure methods are\\napplied, they may remain vulnerable to malicious attacks\\n(Cheng et al., 2017). As a result, their dissemination is\\nrestricted and the data have limited utility (O’Keefe & Ru-\\nbin, 2015). Differential privacy methods (Ji et al., 2014),\\nhomomorphic encryption approaches (Aslett et al., 2015;\\nWood et al., 2020), or federated machine learning (Yang\\net al., 2019; Lin et al., 2021) may be implemented, allowing\\n1Development Economics Data Group, The World Bank, USA.\\nCorrespondence to:\\nAivin V . Solatorio <asolatorio@worldbank.org >\\nGitHub: @avsolatorio.\\nFigure 1. Illustration of the REaLTabFormer model. The left block\\nshows the non-relational tabular data model using GPT-2 with a\\ncausal LM head. In contrast, the right block shows how a relational\\ndataset’s child table is modeled using a sequence-to-sequence\\n(Seq2Seq) model. The Seq2Seq model uses the observations in\\nthe parent table to condition the generation of the observations in\\nthe child table. The trained GPT-2 model on the parent table, with\\nweights frozen, is also used as the encoder in the Seq2Seq model.\\ninsights from sensitive data to be accessible to researchers.\\nSynthetic tabular data with similar statistical properties as\\nthe real data offer an alternative, offering more value espe-\\ncially in granular and segmentation analyses. To comply\\nwith data privacy requirements, the generative models that\\nproduce these synthetic data must provide guarantees that\\n“data copying” does not happen (Meehan et al., 2020; Car-\\nlini et al., 2023).\\nFormally, tabular data is a collection of observations (rows)\\noithat may or may not be independent. A single obser-\\nvation in a tabular data Twithncolumns is deﬁned by\\noi= [xi1,xi2,...,xij,...,xin], andjindicating the jthcol-\\numn. We refer to tabular data having observations indepen-\\ndent of each other as non-relational tabular data . Tabular\\ndata having observations related to each other are referred to\\nasrelational tabular data . Relational datasets have at least\\none pair of tabular data ﬁles with a one-to-many mapping\\nof observations between the parent table and the child table,arXiv:2302.02041v1  [cs.LG]  4 Feb 2023'),\n",
       " Document(metadata={'source': 'RealTabformer.pdf', 'page': 1}, page_content='REaLTabFormer: Generating Realistic Relational and Tabular Data using Transformers\\nrespectively, linked by a unique identiﬁer. In the context of a\\nrelational dataset, a parent table is a non-relational tabular\\ndata, whereas the child table is a relational tabular data.\\nRelational tabular databases model the logical partitioning\\nof data and prevent unnecessary duplication of observations\\nfrom the parent to child tables (Jatana et al., 2012). Despite\\nits ubiquity, limited work has been done in generating syn-\\nthetic relational datasets. This may be due to the challenging\\nnature of modeling the complex relationships within and\\nacross tables.\\nThe ﬁeld of synthetic data generation has seen signiﬁcant\\ndevelopment in recent years (Gupta et al., 2016; Abufadda\\n& Mansour, 2021; Hernandez et al., 2022; Figueira & Vaz,\\n2022). Generative models have become mainstream with the\\nadvent of synthetic image generation models such as DALL-\\nE (Ramesh et al., 2021), and most recently, ChatGPT. While\\ngenerative models for images and text are common, mod-\\nels for producing synthetic tabular data are comparatively\\nlimited despite their multiple possible applications. Syn-\\nthetic tabular data can contribute to addressing data privacy\\nissues and data sparseness (Appenzeller et al., 2022). They\\ncan help to make sensitive data accessible to researchers\\n(Goncalves et al., 2020), and to ﬁll gaps in data availabil-\\nity for counterfactual research and agent-based simulations\\n(Fagiolo et al., 2019), and for synthetic control methods\\n(Abadie et al., 2015). Further value can be derived from\\ntabular data by building predictive models using machine\\nlearning (Shwartz-Ziv & Armon, 2022). These predictive\\nmodels can infer variables of interest in the data that may\\notherwise be expensive to collect or correspond to some\\nsuccess metrics that can guide business decisions. Synthetic\\ndata produced by deep learning models have been shown to\\nperform well in predictive modeling tasks. This extends the\\nutility of real-world data that may otherwise be unused due\\nto privacy concerns.\\nThis paper introduces the REalTabFormer , a transformer-\\nbased framework for generating non-relational tabular data\\nand relational datasets. It makes the following contributions:\\nUniﬁed framework The REalTabFormer uses an autore-\\ngressive (GPT-2) transformer to model non-relational tab-\\nular data for modeling and generating parent tables. It\\nthen models and generates observations in the child ta-\\nble using the sequence-to-sequence (Seq2Seq) (Yun et al.,\\n2019) framework. The encoder network uses the pre-trained\\nweights of the network for the parent table, contextualizing\\nthe input for generating arbitrary-length data corresponding\\nto observations in a child table, via the decoder network.\\nStrategies for privacy-preserving training Synthetic\\ndata generation models must not only be able to generate\\nrealistic data but also implement safeguards to prevent the\\nmodel from “memorizing” and copying observations in the\\ntraining data during sampling. We use the distance to clos-est record (DCR), a data-copying measure, and statistical\\nbootstrapping to detect overﬁtting during training robustly.\\nWe introduce target masking for regularization to reduce the\\nlikelihood of training data being replicated by the model.\\nOpen-sourced models We publish the REaLTabFormer\\nmodels as an open-sourced Python package. Install the\\npackage using: pip install realtabformer .1\\nComprehensive evaluation We evaluate the performance\\nof our models on a variety of real-world datasets. We\\nuse open-sourced state-of-the-art models as baselines to\\nassess the performance of REaLTabFormer in generating\\nnon-relational and relational tabular datasets.\\nOur experiments demonstrate the effectiveness of the RE-\\naLTabFormer model for non-relational tabular data, beating\\ncurrent state-of-the-art in machine learning tasks for large\\ndatasets. We further demonstrate that the synthesized obser-\\nvations for the child table generated by the REaLTabFormer\\ncapture relational statistics more accurately than the baseline\\nmodels.\\n2. Related Work\\nRecent advances in deep learning, such as generative adver-\\nsarial networks (Park et al., 2018; Xu et al., 2019; Zhao et al.,\\n2021), autoencoders (Li et al., 2019; Xu et al., 2019; Darabi\\n& Elor, 2021), language models (Borisov et al., 2022), and\\ndiffusion models (Kotelnikov et al., 2022) have been applied\\nto synthetic non-relational tabular data generation. These\\npapers demonstrate deep learning models’ capacity to pro-\\nduce more realistic data than traditional approaches such as\\nBayesian networks (Xu et al., 2019).\\nOn the other hand, generative models for relational datasets\\nare limited (Patki et al., 2016; Gueye et al., 2022). Exist-\\ning models are based on Hierarchical Modeling Algorithms\\n(Patki et al., 2016) where traditional statistical models, Gaus-\\nsian Copulas, are used to learn the joint distributions for\\neach and across tables. While these models can synthesize\\ndata, the quality of the generated data does not accurately\\ncapture the nuanced conditions within and across tables\\n(Fig. 2 and Fig. 3).\\nPadhi et al. (2021) presented TabGPT for generating syn-\\nthetic transactional data. They showed that autoregressive\\ntransformers, particularly GPT, can synthesize arbitrary-\\nlength data. One limitation of TabGPT is that one has\\nto train independent models to produce transactions for\\neach user. This becomes impractical for real-world applica-\\ntions. Our work generalizes the use of GPT by proposing a\\nsequence-to-sequence framework for generating arbitrary-\\nlength synthetic data conditioned on an input.\\n1https://github.com/avsolatorio/\\nREaLTabFormer'),\n",
       " Document(metadata={'source': 'RealTabformer.pdf', 'page': 2}, page_content='REaLTabFormer: Generating Realistic Relational and Tabular Data using Transformers\\n3. REaLTabFormer\\nREaLTabFormer is a transformer-based framework for gen-\\nerating non-relational tabular data using an autoregres-\\nsive model and relational tabular data using a sequence-\\nto-sequence (Seq2Seq) architecture. The framework also\\nconsists of strategies for encoding tabular data (Section 3.2),\\na statistical method to detect overﬁtting (Section 3.3.2), and\\na constrained sampling strategy during generation.\\nDetails of the framework are described in this section. First,\\nwe present our proposed models to synthesize realistic re-\\nlational datasets. Next, we outline and describe the data\\nprocessing applied to the tabular data as input for train-\\ning the models. We then discuss solutions to improve our\\nmodel’s training and sampling process.\\n3.1. The REaLTabFormer Models\\nParent table model To generate synthetic observations\\nfor a non-relational tabular data T, we model the conditional\\ndistribution of columnar values in each row of the data. Con-\\nsider a single observation oi= [xi1,xi2,...,xij,...,xin]in\\nTas deﬁned earlier. We treat oias a sequence with potential\\ndependencies across values xij, similar to a sentence in a\\ntext. This re-framing provides us with a framework to learn\\nthe conditional distribution xij∼P(X|xi1,xi2,...,xij−1)\\nand sequentially generate the next values in the sequence,\\neventually generating the full observation (Jelinek, 1985;\\nBengio et al., 2000). We use an autoregressive model to\\nlearn this distribution, Fig. 1. In the context of relational\\ndatasets, we use this approach to generate synthetic obser-\\nvations for the parent table T0. We extend this formulation\\nto generate the child table T′—a relational tabular data—\\nassociated with the parent table T0.\\nChild table model The extension is established by in-\\ntroducing a context learned by an encoder network from\\nobservations in T0. Instead of generating oiinT′indepen-\\ndently, we concatenate the child table observations related to\\nthe same observation in T0. This forms an arbitrary-length\\nsequencesi= [o1\\ni,o2\\ni,...,on\\ni], wherenis the number of\\nrelated observations in T′.\\nWe propose to model the generation of sigiven an obser-\\nvation in T0asxn\\nij∼P(X|o1\\ni,...,xn\\ni1,xn\\ni2,...,xn\\nij−1,Ck),\\nwhereCkis a context captured from a related observation\\nin the parent tabular data T0. We also use the same network\\ntrained on the parent table, with weights frozen , as the\\nSeq2Seq model’s encoder. This choice is expected to speed\\nup the training process since only the cross-attention layer\\nand the decoder network are needed to be trained for the\\nchild table model. The encoder network is assumed to have\\nlearned the properties of the parent table and will transfer\\nthis information to the decoder without further ﬁne-tuning\\nits weights, Fig 1.\\nJun\\n2015Jul08 15 22 29 06 13 20 27\\nDate0200040006000800010000Average salesOriginal\\nREaLT abFormer\\nSDVFigure 2. Graph of the daily mean of the Sales variable computed\\nfrom the original Rossmann dataset (blue), synthetic data produced\\nby REaLTabFormer (orange), and data generated by SDV (green).\\nThe REaLTabFormer closely captures the seasonality in the data\\ncompared with the HMA model from the SDV .\\nGPT-2: an autoregressive transformer Previous works\\nhave shown that transformer-based autoregressive models\\ncan capture the conditional distribution of sequential data\\nvery well (Radford et al., 2019; Padhi et al., 2021). RE-\\naLTabFormer uses the GPT-2 architecture—a transformer-\\ndecoder architecture designed for autoregressive tasks—as\\nits base model. We adopt the same architecture for all GPT-2\\ninstances in the framework for simplicity. The GPT-2 archi-\\ntecture used in the REaLTabFormer has 768-dimensional\\nembeddings, 6 decoder layers, and 12 attention heads—a\\nset of parameters similar to DistilGPT2. We use the imple-\\nmentation from the HuggingFace transformers library (Wolf\\net al., 2020).\\n3.2. Tabular Data Encoding\\nThe GReaT model that uses pretrained large language mod-\\nels (LLMs) proposed by Borisov et al. (2022) offers insight\\ninto the minimal data processing requirements for language\\nmodels in generating tabular data. There is, however, the\\npotential for optimization in using autoregressive language\\nmodels for this task, as the ﬁne-tuning process of a large\\npretrained model incurs computational costs. Particularly,\\nLLMs are trained on a large vocabulary where most of the\\ntokens are not needed for generating the tabular data at\\nhand. These unnecessary tokens increase the model’s com-\\nputational requirements and prolong training and sampling\\ntimes. To improve the efﬁciency of our model, we adopt\\na ﬁxed-set vocabulary as initially proposed by Padhi et al.\\n(2021). Generating a ﬁxed vocabulary for each column in\\nthe tabular data offers various advantages in training perfor-\\nmance and sampling. One of the main advantages is being'),\n",
       " Document(metadata={'source': 'RealTabformer.pdf', 'page': 3}, page_content='REaLTabFormer: Generating Realistic Relational and Tabular Data using Transformers\\n20-30 30-40 40-50 50-60 60-70 70-80 80-90 90+\\nage_group-unknown-\\nAndroid App ...\\nAndroid Phone\\nBlackberry\\nChromebook\\nLinux Desktop\\nMac Desktop\\nT ablet\\nWindows Desktop\\n_rtf_other_\\niPad T ablet\\niPhone\\niPodtouchdevice_typeOriginal\\n20-30 30-40 40-50 50-60 60-70 70-80 80-90 90+\\nage_groupSDV\\n20-30 30-40 40-50 50-60 60-70 70-80 80-90 90+\\nage_groupREaLT abFormer\\n0.00.20.40.60.81.0\\nFigure 3. Joint distributions of the agegroup variable in the parent table and the device type in the child table of the Airbnb test\\ndataset (left), the SDV (middle), and the REalTabFormer (right). The plots show that the REaLTabFormer can synthesize values across the\\ndomain of the variables, while SDV learned only two device types out of thirteen. The REaLTabFormer also generalized and imputed age\\nvalues for users with “iPodtouch” device (red box). This device type group has missing values for age in the original data.\\nable to ﬁlter irrelevant tokens when generating values for\\na speciﬁc column. This directly contributes to efﬁciency\\nin sampling by reducing the chances of generating invalid\\nsamples. Our model performs minimal transformation of\\nthe raw data. First, we identify the various data types for\\neach column in the data. We then perform a series of data\\nprocessing speciﬁc to the column and data type. Notably,\\nwe adopt a fully text-based strategy in handling numeri-\\ncal values. These transformations produce a transformed\\ntabular data used to train the model. Borisov et al. (2022)\\nshowed that variable order has an insigniﬁcant impact on\\nlanguage models, so we did not apply variable permutation.\\nWe discuss the processing for each data type in Appendix A.\\nTraining data for the parent table The GPT-2 model we\\nuse requires a set of token ids as input. To generate these\\nsequences of token ids, we ﬁrst create a vocabulary. This\\nvocabulary maps the unique tokens in each column to a\\nunique token id. Then, for each row in the modiﬁed data,\\nwe apply the mapping in the vocabulary to the tokens. This\\nproduces a list of token ids for each row of the data. The\\nmodel is then trained on an autoregressive task wherein the\\ntarget data corresponds to the right-shifted tokens of the\\ninput data.\\nTraining data for the child table We concatenate the\\ntransformed observations corresponding to related rows in\\nthe child table. A special token is added before and after\\nthe set of tokens representing an individual observation.\\nIn this form, the data we use to train the Seq2Seq model\\ncontains input-output pairs. An input value contains a ﬁxed-\\nlength array of token ids representing the observation in\\nthe parent table. The input is similar to the input used\\nin the parent table model. An arbitrary-length array with\\nthe concatenated token ids for each related observation in\\nthe child table represents the output value. The number\\nof related observations that can be modeled is limited by\\ncomputational resources.3.3. REaLTabFormer Training and Sampling\\nDeep learning models for generative tasks face challenges of\\noverﬁtting the data resulting in issues such as data-copying\\n(Meehan et al., 2020; Carlini et al., 2023). Furthermore,\\nobservations generated by generative models for tabular\\ndata could face issues of validity and inconsistency. These\\nissues in the generated samples impact the efﬁciency of the\\ngenerative process. Our proposed framework addresses the\\naforementioned issues by, (i) introducing a robust statistical\\nmethod to monitor overﬁtting, and (ii) target masking to fur-\\nther reduce the risk of data copying. To improve the rate of\\nproducing valid observations by the model, we also imple-\\nment a constrained generation strategy during the sampling\\nstage.\\n3.3.1. T ARGET MASKING\\nData copying is a critical issue for deep learning-based gen-\\nerative tabular models as it can expose and compromise\\nsensitive information in the training data. To mitigate data-\\ncopying, we introduce target masking . Target masking is a\\nform of regularization aimed at minimizing the likelihood of\\nrecords in the training data being “memorized” and copied\\nby the generative model. Unlike the token masking intro-\\nduced in BERT (Devlin et al., 2018), where input tokens\\nare masked and the model is expected to predict the correct\\ntoken, target masking implements random replacement of\\nthe target or label tokens with a special mask token. This\\nartiﬁcially introduces missing values in the data.\\nWe intend for the model to learn the masks instead of the ac-\\ntual values. During the sampling stage, we then restrict the\\nmask token generation, forcing the model to ﬁll the value\\nwith a valid token probabilistically. Notably, even when the\\nmodel learns to copy the input-output pair, the learned out-\\nput corresponds to the masked version of the input. There-\\nfore, when we process the output, the probabilistic nature of\\nreplacing the mask token reduces the likelihood of generat-'),\n",
       " Document(metadata={'source': 'RealTabformer.pdf', 'page': 4}, page_content='REaLTabFormer: Generating Realistic Relational and Tabular Data using Transformers\\ning the training data. The mask rate parameter controls the\\nproportion of the tokens that are masked. We use a mask\\nrate of 10% in our experiments.\\n3.3.2. O VERFITTING ASSESSMENT\\nApplying deep learning models to small datasets may easily\\nresult in overﬁtting. This may cause privacy-related issues\\nwhen the model generates observations that are copied from\\nthe training data. Knowing when the model overﬁts the data\\nis also crucial when the purpose is to generate diverse out-of-\\nsample data. An overﬁtted model tends to generate samples\\ngenerally closer to the training data, thereby limiting the\\ngeneralization capacity of the model. While the former issue\\ncan be resolved by post-generation ﬁltering, the latter must\\nbe detected during the model training.\\nTaking hold-out data to detect overﬁtting is a common strat-\\negy in machine learning. Unfortunately, this strategy could\\nresult in the premature termination of model training. It\\nmay also penalize a model based only on a small subset\\nof the data (Blum et al., 1999). The training procedures of\\nexisting state-of-the-art models do not explicitly check for\\noverﬁtting (Xu et al., 2019; Borisov et al., 2022; Kotelnikov\\net al., 2022). We propose and describe below an empiri-\\ncal statistical method to inform the generative model when\\noverﬁtting happens. The method allows for the full data to\\nbe used in the training without the need for a hold-out set.\\nThe design of the method is expected to also help prevent\\ndata copying and the production of data that is riskily close\\nto the training data.\\nDistance to closest record We use the distance to the\\nclosest record (DCR) (Park et al., 2018) to measure the\\nsimilarity of synthetic samples to the original data. The\\nDCR is evaluated by taking a speciﬁed distance metric L\\nbetween the training data Trand the generated data G. We\\nthen ﬁnd the smallest distance for each record. Consider the\\ndistance matrix between TrandG,\\nD=L(Tr,G) (1)\\nThe minimum value in each row iofDis the minimum\\ndistance of the ithrecord in the training data with respect\\nto all records in the generated data. We denote this set of\\nminimum values as ⃗di. The minimum value in each column\\njofDis the minimum distance of the jthrecord in the\\ngenerated data with respect to all records in the training\\ndata. We denote this set of minimum values as ⃗dj. We then\\ntake⃗dg= [⃗di,⃗dj]as the distribution of distances to closest\\nrecords between the training data and the generated data.\\nWe deﬁne the quantity\\n⃗d= [⃗di,⃗dj] (2)\\nas the distance to closest record distribution for some Trandsome arbitrary sample. We also derive the DCR between\\nthe train dataset and some hold-out data Th. Let us denote\\nthis distribution of distances as ⃗dh. We use the distributions\\n⃗dgand⃗dhin our proposed non-parametric method.\\nQuantile difference ( Qδ) statistic Two samples from a\\nsimilar distribution should, on average, have approximately\\nthe same values at each quantile of the distribution. To detect\\nwhether two samples come from different distributions, we\\ndeﬁne a set of quantiles over which we compare the two\\nsamples. For each quantile in the set, we ﬁnd the value at\\nthe given quantile in one sample and measure the proportion\\nof the values in the other sample that are below it. If the\\ndistributions are similar, the proportion should be close to\\nthe given quantile, for all quantiles being tested.\\nFormally, let ShandSghavingmandnobservations, re-\\nspectively, be two samples being compared. Let Qbe a\\nset ofNquantiles, and q∈Qis a speciﬁc quantile in the\\nset. Consider vqas the value in Shat quantileq. Then, we\\ncompute the value\\npq=∑\\nx∈Sg[x≤vq]\\nn(3)\\nwherepqis the proportion of values in Sgthat are less than\\nor equal tovq. We deﬁne a statistic\\nQδ=1\\nN∑\\nq(pq−q) (4)\\nThis formulation has similarities with the Cramer-von Mises\\nω2criterion, but the Qδstatistic has one key difference: the\\nasymmetry of the statistic. This stems from the fact that\\nthe choice of which sample is considered as Sh—the dis-\\ntribution from which vqis identiﬁed—matters. Since we\\nare averaging over the quantiles, this statistic may not yield\\nconclusive guidance for distributions with cumulative dis-\\ntribution functions (CDFs) intersecting at some quantile.\\nNonetheless, this statistic works best in detecting the dissim-\\nilarity of the two samples at the left tail of the distribution\\nwhich matters most for our purpose. This is because the\\ndistributions we are comparing are the DCRs. We want\\nto detect when the distance between the sample and the\\ntraining data is signiﬁcantly closer to zero than expected.\\nWe use theQδstatistic as the basis for detecting overﬁtting.\\nThe threshold against which this statistic will be compared\\nduring training is produced through an empirical bootstrap-\\nping over random samples from the training data. The\\ndetails of the bootstrapping method are explained next.\\nQδstatistic threshold via bootstrapping We use three\\nhyperparameters in estimating the threshold that will signal\\nwhen overﬁtting occurs during training. First, a sample pro-\\nportionρcorresponds to a fraction of the training data. This'),\n",
       " Document(metadata={'source': 'RealTabformer.pdf', 'page': 5}, page_content='REaLTabFormer: Generating Realistic Relational and Tabular Data using Transformers\\nTable 1. Machine learning efﬁcacy (MLE) and discriminator measure (DM) evaluated on the synthetic data generated by the models\\n(columns) trained on six real-world datasets (rows): Abalone (AB), Adult income (AD), Buddy (BU), California housing (CA), Diabetes\\n(DI), and Facebook Comments (FB). The MLE is measured by the R2for regression, while macro average F1is used for classiﬁcation\\ntasks; higher scores are better. A discriminator measure closer to 50% is better. Best scores are highlighted for the MLE measure,\\nconsidering standard deviation. No reported results for GReaT on the FB dataset due to impractical training time.\\nOriginal TV AE CTABGAN+ Tab-DDPM GReaT REaLTabFormer\\nAB (R2)MLE ( ↑) 0.5562 ±0.004 0.3943 ±0.012 0.4697 ±0.014 0.5248 ±0.011 0.3530 ±0.031 0.5035 ±0.011\\nDM ( ↓) - 82.96 ±2.42 75.64±1.20 59.88±2.22 70.46±0.92 63.08±1.18\\nAD (F1)MLE 0.8155 ±0.001 0.7695 ±0.004 0.7778 ±0.003 0.7922 ±0.002 0.7997 ±0.002 0.8113 ±0.002\\nDM - 95.48 ±1.34 61.17±0.40 53.73±0.22 68.04±0.26 55.78±0.20\\nBU (F1)MLE 0.9303 ±0.002 0.9233 ±0.002 0.9267 ±0.002 0.9057 ±0.003 0.9279 ±0.003 0.9278 ±0.003\\nDM - 66.56 ±0.56 58.33±0.49 54.43±0.47 62.18±0.45 55.86±0.47\\nCA (R2)MLE 0.8568 ±0.001 0.7373 ±0.004 0.5231 ±0.006 0.8252 ±0.002 0.7189 ±0.004 0.8076 ±0.003\\nDM - 62.06 ±0.60 90.14±1.03 54.30±0.89 66.78±0.47 57.29±0.56\\nDI (F1)MLE 0.7759 ±0.014 0.7395 ±0.035 0.7339 ±0.024 0.7448 ±0.031 0.7419 ±0.03 0.7315 ±0.027\\nDM - 90.16 ±1.31 70.94±1.99 69.00±1.56 74.88±1.79 75.56±2.84\\nFB (R2)MLE 0.8371 ±0.001 0.6374 ±0.007 0.4722 ±0.053 0.6850 ±0.006 - 0.7702 ±0.004\\nDM - 97.72 ±0.80 93.60±0.28 66.07±0.23 - 65.46 ±0.83\\nfraction will be randomly sampled during the bootstrapping\\nand evaluation phases of the generative model training. Sec-\\nond, theαvalue for choosing the critical threshold for the\\nbootstrap statistic. Third, we specify a bootstrap round B\\ncorresponding to the number of times we compute the Qδ\\nstatistic between three random samples—two, each of size\\nρ, and the rest having size 1−2ρof the training data.\\nFormally, for a given training data TrwithNobservations,\\nwe deﬁne a bootstrap method to generate a conﬁdence in-\\nterval for the Qδstatistic speciﬁc to the tabular data at hand.\\nFor each bootstrap round b∈B, we take three random\\nsamplesStr,Sh, andSg, without replacement. ShandSg\\nare each of size ρN, whileStrcontains (1−2ρ)Nsamples.\\nWe compute the DCR distributions ⃗dgand⃗dhfor the two\\nsamplesShandSg, respectively, relative to sample Str. We\\nthen compute the Qδstatistic between ⃗dgand⃗dh, where we\\ntake⃗dhas the distribution from which we compute the value\\nvqin Equation 3. We store the statistic computed across the\\nbootstrap rounds. We use the speciﬁed αto get the cutoff\\nvalue that will be used as the statistic threshold. We use\\nthis threshold Q′\\nδduring training to compare the Qδstatistic\\nderived from the generated samples by the model. We set\\nρ= 0.165,α= 0.95, andB= 500 in our experiments.\\nEarly stopping with Q′\\nδOur training procedure is paused\\nat each epoch that is a multiple of E. We generate data from\\nthe model during these epochs. The generated data has size\\nSg. We then take two mutually exclusive random samples\\nfrom the training data, without replacement, to represent\\nStrandSh. We compute the Qe\\nδfor this epoch based on the\\nsamples generated and drawn. Then, we compare this statis-\\ntic to the previously computed threshold Q′\\nδ. We continuetraining the model if Qe\\nδ< Q′\\nδ. We save a checkpoint of\\nthis model. We terminate the model training when Qe\\nδ>Q′\\nδ\\nforXconsecutive epochs. We then load the checkpoint for\\nthe most recent model that satisﬁed the condition Qe\\nδ<Q′\\nδ.\\nIn our experiments, we set E= 5as the period of our over-\\nﬁtting evaluation and X= 2 as our grace period before\\ntraining termination.\\n3.3.3. S AMPLING\\nThe models we use build each observation sequentially,\\none token at a time. We leverage the structure of our data\\nprocessing to optimize the generation of samples from the\\ntrained models. Using a vocabulary speciﬁc to a column in\\nthe input data allows us to implement a constrained genera-\\ntion of tokens for each column.\\nWe track the token ids that form the domain of each column\\nduring the generation of the vocabulary using a hash map.\\nBased on this, the tokens that are invalid for the columns will\\nnot be considered for generation in the timestep representing\\nthe column. This strategy allows for efﬁcient sampling\\nwherein the likelihood of generating an invalid sample is\\nclose to zero. In our experiments, ≪1%invalid samples\\nare generated during the sampling phase.\\n4. Experiments and Results\\nThis section outlines the evaluation process we conducted to\\nquantify the performance of the proposed REaLTabFormer\\nframework compared with baseline models. We ﬁrst demon-\\nstrate that the performance of the model we use to generate\\nthe parent tables, and non-relational tabular data in gen-\\neral, compares with or exceeds the performance of state-of-'),\n",
       " Document(metadata={'source': 'RealTabformer.pdf', 'page': 6}, page_content='REaLTabFormer: Generating Realistic Relational and Tabular Data using Transformers\\nTable 2. Logistic detection (LD) measure using random forest\\nmodel for the generated parent, child, and merged tables by the\\nHierarchical Modeling Algorithm (HMA) from SDV and the RE-\\naLTabFormer (RTF) models. Our model consistently beats the\\nSDV model on this metric.\\nDATASET TABLE SDV RTF\\nROSSMANNPARENT 31.77 ±3.41 81.04 ±4.54\\nCHILD 6.53±0.39 52.08 ±0.89\\nMERGED 2.80±0.25 28.33 ±2.31\\nAIRBNBPARENT 7.37±0.72 89.65 ±1.92\\nCHILD 0.00±0.00 30.48 ±0.79\\nMERGED 0.00±0.00 21.43 ±1.10\\nthe-art models in real-world tabular data generation tasks\\nmeasured by the machine learning efﬁcacy metric. We also\\nuse the discriminator measure to quantify how realistic the\\nsamples generated by each model are. We proceed to model\\nreal-world relational datasets and show, quantitatively using\\nlogistic detection, that the synthetic data produced by the\\nREaLTabFormer are more realistic and accurate.\\n4.1. Data\\nWe use a collection of real-world datasets, listed in Table 3,\\ncommonly used in previous works for non-relational tabular\\ndata generation (Xu et al., 2019; Zhao et al., 2021; Gor-\\nishniy et al., 2021; Borisov et al., 2022; Kotelnikov et al.,\\n2022). These datasets differ with respect to the number of\\nobservations, ranging from 768 up to 197,080 observations.\\nThere is also variation in the number of variables they con-\\ntain, ranging from 8 to 50 numerical variables and 0 up to 8\\ncategorical variables. The datasets cover regression, binary,\\nand multi-class classiﬁcation prediction tasks.\\nWe use two real-world datasets to compare the performance\\nof the REaLTabFormer on modeling relational tabular data\\ncompared with the baseline. These datasets are the Ross-\\nmann dataset and the Airbnb dataset used in prior work on\\nsynthetic relation data generation (Patki et al., 2016).\\n4.2. Baseline models\\nNon-relational tabular data We use models that apply\\ndifferent deep learning architectures for generating non-\\nrelational tabular data as baselines to compare the REaLTab-\\nFormer model with. The TV AE is based on variational\\nautoencoder (Xu et al., 2019), the CTABGAN+ on GAN\\narchitecture (Zhao et al., 2022), the Tab-DDPM on diffusion\\n(Kotelnikov et al., 2022), and GReaT uses pretrained LLM\\n(Borisov et al., 2022).\\nRelational datasets Models for generating relational\\ndatasets are limited. Gueye et al. (2022) published work on\\nusing GAN for relational datasets but no open-sourced im-\\na b c d\\nStoreType0200040006000800010000SalesData\\nOriginal\\nREaLT abFormer\\nSDVFigure 4. Summary of the average “Sales” variable in the child\\ntable of the Rossmann dataset grouped by “StoreType” variable in\\nthe parent table. The values shown are from the original data (blue),\\nsynthetic data produced by REaLTabFormer (orange), and data\\ngenerated by SDV (green). This graph shows that REaLTabFormer\\ncaptures the inter-table variations and relationships well.\\nplementation is available. We choose to limit our baselines\\nto open-sourced models; hence, we only use the Hierarchi-\\ncal Modeling Algorithm (HMA) available in the Synthetic\\nData Vault (SDV) as our baseline (Patki et al., 2016).\\n4.3. Generative models training\\nThe GReaT model was trained for 100 epochs for each\\ndata. The parameters for the TV AE, CTABGAN+, and\\nTab-DDPM models had been tuned for the predictive task\\nitself using the real validation data from Kotelnikov et al.\\n(2022). For the relational datasets, we trained the HMA\\nmodel as prescribed in the SDV documentation. In contrast,\\nthe REaLTabFormer model was not tuned against any of\\nthe machine learning tasks. The model solely relied on the\\noverﬁtting metric discussed in Section 3.3.2. We used the\\nsame parameters for the different datasets to test how the\\nREaLTabFormer performs “out-of-the-box”.\\n4.4. Measures and Results\\nWe select the following measures to quantify the quality and\\nutility of the generated samples by the generative models.\\nMachine Learning (ML) efﬁcacy The machine learning\\n(ML) efﬁcacy (Xu et al., 2019; Kotelnikov et al., 2022;\\nBorisov et al., 2022) measures the potential utility of the\\nsynthetic data to supplant the real data for machine learn-\\ning tasks, in particular, training a prediction model. The\\nML efﬁcacy reported by Borisov et al. (2022) in their work\\nused ML models that were not ﬁne-tuned. Kotelnikov et al.'),\n",
       " Document(metadata={'source': 'RealTabformer.pdf', 'page': 7}, page_content='REaLTabFormer: Generating Realistic Relational and Tabular Data using Transformers\\n(2022) showed that the ML efﬁcacy computed from models\\nthat are not ﬁne-tuned may show spurious results. They in-\\nstead optimized the ML models—CatBoost (Prokhorenkova\\net al., 2018)—they used in reporting the ML efﬁcacy. This\\napproach is closer to what researchers are expected to do\\nin the real world, therefore, we adopt these tuned models\\nin our experiments. We generate a validation set from the\\ngenerative models to signal the early-stopping condition\\nduring the ML model training. This is in contrast with the\\nmethod used by Kotelnikov et al. (2022) where they still\\nrelied on the real validation data for the early-stopping of\\nthe ML model.\\nWe report the macro average F1 score (Opitz & Burst, 2019)\\nfor classiﬁcation tasks and the R2metric for regression\\ntasks. Our results presented in Table 1 (MLE) show that\\nREaLTabFormer, despite not being ﬁne-tuned, produces ML\\nefﬁcacy scores that are the best or second-best compared\\nwith the baselines. This demonstrates that REaLTabFormer\\ncan be used, “out-of-the-box”, to generate synthetic data\\nwith state-of-the-art performance in machine learning tasks.\\nThe FB comments dataset, where REaLTabFormer obtained\\nthe best performance, is the largest dataset tested and has\\nthe largest number of columns. Training the GReaT model\\non this dataset yielded impractical runtime so no result is\\nreported. This supports our view that using LLM trained\\non a large vocabulary, containing a majority of irrelevant\\ntokens, limits the efﬁciency of the model.\\nDiscriminator measure We adopt the discriminator mea-\\nsure (Borisov et al., 2022) to quantify whether the data\\ngenerated by a model is easily distinguishable from real\\ndata. A dataset is made by combining an equal number of\\nreal and synthetic data. Real observations in this dataset are\\nlabeled as “1” and synthetic observations are labeled as “0”.\\nSimilar to Borisov et al. (2022), we train a random forest\\nmodel to predict the labels given an observation. A held-out\\ndataset containing a combination of synthetic samples and\\nreal test data is then used to report the ﬁnal measure.\\nAn accuracy that is closer to 50% implies better synthetic\\ndata quality since the discriminative model is not able to\\ndistinguish the real from the synthetic observations. We\\nreport our results in Table 1 (DM). The DM measure shows\\nthat the Tab-DDPM has the most indistinguishable synthetic\\ndata. Nonetheless, REaLTabFormer, without the need for\\ntuning, has DM measures that are close to the Tab-DDPM.\\nThis suggests that the synthetic data produced by a diffusion-\\nbased model and REaLTabFormer are realistic compared\\nwith the other baselines.\\nLogistic Detection For relational datasets, we use logistic\\ndetection (LD) (Fisher et al., 2019; Gueye et al., 2022) to\\nquantify the quality of the parent, child, and merged tables\\ngenerated by REaLTabFormer compared with the HMAmodel. We evaluate ROC-AUC scores averaged over (N=3)\\ncross-validation folds,\\nµRA=1\\nNN∑\\ni=1max(0.5,ROC−AUC)×2−1 (5)\\nThe value reported is LD= 100×(1−µRA), where scores\\nrange from 0 to 100, and scores closer to 100 imply better\\nsynthetic data quality. We use random forest in measuring\\nthe logistic detection instead of the standard logistic regres-\\nsion model. The random forest model captures non-linearity\\nin the data well than logistic regression (Couronn ´e et al.,\\n2018), reducing the likelihood of spurious results. We report\\nthe results in Table 2. Additional LD results using logistic\\nregression are shown in Table 4.\\nThe REaLTabFormer model produces signiﬁcantly higher-\\nquality synthetic data than the HMA model across the\\ndatasets tested. The high values of LD for the child and\\nthe merged tables highlight the ability of REaLTabFormer\\nto accurately synthesize relational datasets in comparison\\nwith the leading baseline. The LD metric shows that data\\ngenerated by SDV for the Airbnb child table is entirely dis-\\ntinguishable from the real data. The quantitative results are\\nsupported by relational statistics computed from synthetic\\ndatasets produced by REaLTabFormer and the HMA model:\\nFigures 2 to 4.\\n5. Conclusion\\nWe presented REaLTabFormer, a framework capable of\\ngenerating high-quality non-relational tabular data and re-\\nlational datasets. This work extends the application of\\nsequence-to-sequence models to modeling and generating\\nrelational datasets. We introduced target masking as a com-\\nponent in the model to mitigate data-copying and safeguard-\\ning from potentially sensitive data leaking from the training\\ndata. We proposed a statistical method and the Qδstatistic\\nfor detecting overﬁtting in model training. This statistical\\nmethod may be adapted to other generative model training.\\nWe showed that our proposed model generates realistic syn-\\nthetic tabular data that can be a proxy for real-world data in\\nmachine learning tasks. REaLTabFormer’s ability to model\\nrelational datasets accurately compared with existing open-\\nsourced alternative contributes to solving existing gaps in\\ngenerative models for realistic relational datasets. Finally,\\nthis work can be extended and applied to data imputation,\\ncross-survey imputation, and upsampling for machine learn-\\ning with imbalanced data. A BERT-like encoder can be used\\ninstead of GPT-2 with the REaLTabFormer for modeling\\nrelational datasets. We also see opportunities to improve\\nprivacy protection strategies and the development of more\\ncomponents like target masking embedded into synthetic\\ndata generation models to prevent sensitive data exposure.'),\n",
       " Document(metadata={'source': 'RealTabformer.pdf', 'page': 8}, page_content='REaLTabFormer: Generating Realistic Relational and Tabular Data using Transformers\\n6. REaLTabFormer Python Package\\nWe publish the REaLTabFormer as a package on PyPi. We\\nshow below how the model can be easily trained on any\\ntabular dataset, loaded as a Pandas DataFrame.\\n6.1. Non-relational tabular model\\nUse the following snippet to ﬁt the REaLTabFormer on a\\nnon-relational tabular dataset. One can control the various\\nhyper-parameters of the model and the ﬁtting method, e.g.,\\nthe number of bootstrap rounds numbootstrap , the frac-\\ntion of training data frac used to generate the Qδstatistic,\\netc. Keyword arguments for the HuggingFace transformers\\nTrainer class can also be passed as **kwargs when\\ninitializing the model.\\n1# pip install realtabformer\\n2import pandas as pd\\n3from realtabformer import REaLTabFormer\\n4\\n5# NOTE: Remove any unique identifiers in the\\n6# data that you don\\'t want to be modeled.\\n7df = pd.read_csv(\"foo.csv\")\\n8\\n9# Non-relational or parent table.\\n10rtf_model = REaLTabFormer(\\n11 model_type=\"tabular\",\\n12 gradient_accumulation_steps=4)\\n13\\n14# Fit the model on the dataset.\\n15# Additional parameters can be\\n16# passed to the /grave.ts1.fit /grave.ts1method.\\n17rtf_model.fit(df)\\n18\\n19# Save the model to the current directory.\\n20# A new directory /grave.ts1rtf_model/ /grave.ts1will be created.\\n21# In it, a directory with the model\\'s\\n22# experiment id /grave.ts1idXXXX /grave.ts1will also be created\\n23# where the artefacts of the model will be stored.\\n24rtf_model.save(\"rtf_model/\")\\n25\\n26# Generate synthetic data with the same\\n27# number of observations as the real dataset.\\n28samples = rtf_model.sample(n_samples=len(df))\\n29\\n30# Load the saved model. The directory to the\\n31# experiment must be provided.\\n32rtf_model2 = REaLTabFormer.load_from_dir(\\n33 path=\"rtf_model/idXXXX\")\\n6.2. Non-relational tabular model\\nREaLTabFormer for relational databases requires a two-\\nphase training. First, the model for the parent table is trained\\nas a non-relational tabular data, then saved. Second, we\\npass the path of the saved parent model when creating the\\nREaLTabFormer instance for the child model to be used as\\nits encoder, then train. Generate synthetic samples from the\\nparent table and use as input to the trained child model to\\ngenerate the synthetic relational observations.1# pip install realtabformer\\n2import os\\n3import pandas as pd\\n4from realtabformer import REaLTabFormer\\n5\\n6pdir = Path(\"rtf_parent/\")\\n7parent_df = pd.read_csv(\"foo.csv\")\\n8child_df = pd.read_csv(\"bar.csv\")\\n9join_on = \"unique_id\"\\n10\\n11# Make sure that the key columns in both the\\n12# parent and the child table have the same name.\\n13assert ((join_on inparent_df.columns) and\\n14 (join_on inchild_df.columns))\\n15\\n16# Non-relational or parent table. Don\\'t include the\\n17# unique_id field.\\n18parent_model = REaLTabFormer(model_type=\"tabular\")\\n19parent_model.fit(parent_df.drop(join_on, axis=1))\\n20parent_model.save(pdir)\\n21\\n22# # Get the most recently saved parent model,\\n23# # or a specify some other saved model.\\n24# parent_model_path = pdir / \"idXXX\"\\n25parent_model_path = sorted([\\n26 pfor pinpdir.glob(\"id *\")ifp.is_dir()],\\n27 key=os.path.getmtime)[-1]\\n28\\n29child_model = REaLTabFormer(\\n30 model_type=\"relational\",\\n31 parent_realtabformer_path=parent_model_path,\\n32 output_max_length= None , train_size=0.8)\\n33\\n34child_model.fit(\\n35 df=child_df, in_df=parent_df, join_on=join_on)\\n36\\n37# Generate parent samples.\\n38parent_samples = parent_model.sample(len(parend_df))\\n39\\n40# Create the unique ids based on the index.\\n41parent_samples.index.name = join_on\\n42parent_samples = parent_samples.reset_index()\\n43\\n44# Generate the relational observations.\\n45child_samples = child_model.sample(\\n46 input_unique_ids=parent_samples[join_on],\\n47 input_df=parent_samples.drop(join_on, axis=1),\\n48 gen_batch=64)\\nAcknowledgments This project was supported by the\\n“Enhancing Responsible Microdata Access to Improve\\nPolicy and Response in Forced Displacement Situations”\\nproject funded by the World Bank-UNHCR Joint Data Cen-\\nter on Forced Displacement (JDC) – KP-P174174-GINP-\\nTF0B5124. We also thank Patrick Brock for providing\\ninsightful comments. The ﬁndings, interpretations, and\\nconclusions expressed in this paper are entirely those of\\nthe authors. They do not necessarily represent the views\\nof the International Bank for Reconstruction and Develop-\\nment/World Bank and its afﬁliated organizations, or those\\nof the Executive Directors of the World Bank or the govern-\\nments they represent.'),\n",
       " Document(metadata={'source': 'RealTabformer.pdf', 'page': 9}, page_content='REaLTabFormer: Generating Realistic Relational and Tabular Data using Transformers\\nReferences\\nAbadie, A., Diamond, A., and Hainmueller, J. Compara-\\ntive politics and the synthetic control method. American\\nJournal of Political Science , 59(2):495–510, 2015.\\nAbdelhameed, S. A., Moussa, S. M., and Khalifa, M. E.\\nPrivacy-preserving tabular data publishing: a comprehen-\\nsive evaluation from web to cloud. Computers & Security ,\\n72:74–95, 2018.\\nAbufadda, M. and Mansour, K. A survey of synthetic data\\ngeneration for machine learning. In 2021 22nd Inter-\\nnational Arab Conference on Information Technology\\n(ACIT) , pp. 1–7. IEEE, 2021.\\nAppenzeller, A., Leitner, M., Philipp, P., Krempel, E., and\\nBeyerer, J. Privacy and utility of private synthetic data for\\nmedical data analyses. Applied Sciences , 12(23):12320,\\n2022.\\nAslett, L. J., Esperan c ¸a, P. M., and Holmes, C. C. A re-\\nview of homomorphic encryption and software tools for\\nencrypted statistical machine learning. arXiv preprint\\narXiv:1508.06574 , 2015.\\nBengio, Y ., Ducharme, R., and Vincent, P. A neural proba-\\nbilistic language model. Advances in neural information\\nprocessing systems , 13, 2000.\\nBlum, A., Kalai, A., and Langford, J. Beating the hold-out:\\nBounds for k-fold and progressive cross-validation. In\\nProceedings of the twelfth annual conference on Compu-\\ntational learning theory , pp. 203–208, 1999.\\nBorisov, V ., Seßler, K., Leemann, T., Pawelczyk, M., and\\nKasneci, G. Language Models are Realistic Tabular Data\\nGenerators, October 2022. arXiv:2210.06280 [cs].\\nCarlini, N., Hayes, J., Nasr, M., Jagielski, M., Sehwag,\\nV ., Tram `er, F., Balle, B., Ippolito, D., and Wallace, E.\\nExtracting training data from diffusion models. arXiv\\npreprint arXiv:2301.13188 , 2023.\\nCheng, L., Liu, F., and Yao, D. Enterprise data breach:\\ncauses, challenges, prevention, and future directions. Wi-\\nley Interdisciplinary Reviews: Data Mining and Knowl-\\nedge Discovery , 7(5):e1211, 2017.\\nCouronn ´e, R., Probst, P., and Boulesteix, A.-L. Random\\nforest versus logistic regression: a large-scale benchmark\\nexperiment. BMC bioinformatics , 19:1–14, 2018.\\nDarabi, S. and Elor, Y . Synthesising multi-modal\\nminority samples for tabular data. arXiv preprint\\narXiv:2105.08204 , 2021.Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. Bert:\\nPre-training of deep bidirectional transformers for lan-\\nguage understanding. arXiv preprint arXiv:1810.04805 ,\\n2018.\\nFagiolo, G., Guerini, M., Lamperti, F., Moneta, A., and\\nRoventini, A. Validation of agent-based models in eco-\\nnomics and ﬁnance. In Computer simulation validation ,\\npp. 763–787. Springer, 2019.\\nFigueira, A. and Vaz, B. Survey on synthetic data generation,\\nevaluation methods and gans. Mathematics , 10(15):2733,\\n2022.\\nFisher, C. K., Smith, A. M., and Walsh, J. R. Machine\\nlearning for comprehensive forecasting of alzheimer’s\\ndisease progression. Scientiﬁc reports , 9(1):1–14, 2019.\\nGoncalves, A., Ray, P., Soper, B., Stevens, J., Coyle, L.,\\nand Sales, A. P. Generation and evaluation of synthetic\\npatient data. BMC medical research methodology , 20(1):\\n1–40, 2020.\\nGorishniy, Y ., Rubachev, I., Khrulkov, V ., and Babenko,\\nA. Revisiting deep learning models for tabular data. Ad-\\nvances in Neural Information Processing Systems , 34:\\n18932–18943, 2021.\\nGueye, M., Attabi, Y ., and Dumas, M. Row conditional-\\ntgan for generating synthetic relational databases. arXiv\\npreprint arXiv:2211.07588 , 2022.\\nGupta, A., Vedaldi, A., and Zisserman, A. Synthetic data\\nfor text localisation in natural images. In Proceedings\\nof the IEEE conference on computer vision and pattern\\nrecognition , pp. 2315–2324, 2016.\\nHernandez, M., Epelde, G., Alberdi, A., Cilla, R., and\\nRankin, D. Synthetic data generation for tabular health\\nrecords: A systematic review. Neurocomputing , 2022.\\nJatana, N., Puri, S., Ahuja, M., Kathuria, I., and Gosain, D.\\nA survey and comparison of relational and non-relational\\ndatabase. International Journal of Engineering Research\\n& Technology , 1(6):1–5, 2012.\\nJelinek, F. Markov source modeling of text generation. In\\nThe impact of processing techniques on communications ,\\npp. 569–591. Springer, 1985.\\nJi, Z., Lipton, Z. C., and Elkan, C. Differential privacy and\\nmachine learning: a survey and review. arXiv preprint\\narXiv:1412.7584 , 2014.\\nKotelnikov, A., Baranchuk, D., Rubachev, I., and Babenko,\\nA. Tabddpm: Modelling tabular data with diffusion mod-\\nels.arXiv preprint arXiv:2209.15421 , 2022.'),\n",
       " Document(metadata={'source': 'RealTabformer.pdf', 'page': 10}, page_content='REaLTabFormer: Generating Realistic Relational and Tabular Data using Transformers\\nLi, S.-C., Tai, B.-C., and Huang, Y . Evaluating variational\\nautoencoder as a private data release mechanism for tab-\\nular data. In 2019 IEEE 24th Paciﬁc Rim International\\nSymposium on Dependable Computing (PRDC) , pp. 198–\\n1988. IEEE, 2019.\\nLin, J., Ma, J., and Zhu, J. Privacy-preserving house-\\nhold characteristic identiﬁcation with federated learning\\nmethod. IEEE Transactions on Smart Grid , 13(2):1088–\\n1099, 2021.\\nMeehan, C., Chaudhuri, K., and Dasgupta, S. A non-\\nparametric test to detect data-copying in generative mod-\\nels. In International Conference on Artiﬁcial Intelligence\\nand Statistics , 2020.\\nO’Keefe, C. M. and Rubin, D. B. Individual privacy versus\\npublic good: protecting conﬁdentiality in health research.\\nStatistics in medicine , 34(23):3081–3103, 2015.\\nOpitz, J. and Burst, S. Macro f1 and macro f1. arXiv\\npreprint arXiv:1911.03347 , 2019.\\nPadhi, I., Schiff, Y ., Melnyk, I., Rigotti, M., Mroueh, Y .,\\nDognin, P., Ross, J., Nair, R., and Altman, E. Tabular\\nTransformers for Modeling Multivariate Time Series. In-\\nstitute of Electrical and Electronics Engineers Inc., June\\n2021. doi: 10.1109/ICASSP39728.2021.9414142. ISSN:\\n15206149.\\nPark, N., Mohammadi, M., Gorde, K., Jajodia, S., Park,\\nH., and Kim, Y . Data synthesis based on generative\\nadversarial networks. arXiv preprint arXiv:1806.03384 ,\\n2018.\\nPatki, N., Wedge, R., and Veeramachaneni, K. The Synthetic\\nData Vault. In 2016 IEEE International Conference on\\nData Science and Advanced Analytics (DSAA) , pp. 399–\\n410, 2016. doi: 10.1109/DSAA.2016.49.\\nProkhorenkova, L., Gusev, G., V orobev, A., Dorogush, A. V .,\\nand Gulin, A. Catboost: unbiased boosting with categori-\\ncal features. Advances in neural information processing\\nsystems , 31, 2018.\\nRadford, A., Wu, J., Child, R., Luan, D., Amodei, D., and\\nSutskever, I. Language Models are Unsupervised Multi-\\ntask Learners. 2019.\\nRamesh, A., Pavlov, M., Goh, G., Gray, S., V oss, C., Rad-\\nford, A., Chen, M., and Sutskever, I. Zero-shot text-\\nto-image generation. In International Conference on\\nMachine Learning , pp. 8821–8831. PMLR, 2021.\\nShwartz-Ziv, R. and Armon, A. Tabular data: Deep learning\\nis not all you need. Information Fusion , 81:84–90, 2022.Wolf, T., Debut, L., Sanh, V ., Chaumond, J., Delangue, C.,\\nMoi, A., Cistac, P., Rault, T., Louf, R., Funtowicz, M.,\\nDavison, J., Shleifer, S., von Platen, P., Ma, C., Jernite,\\nY ., Plu, J., Xu, C., Le Scao, T., Gugger, S., Drame, M.,\\nLhoest, Q., and Rush, A. Transformers: State-of-the-Art\\nNatural Language Processing. In Proceedings of the 2020\\nConference on Empirical Methods in Natural Language\\nProcessing: System Demonstrations , pp. 38–45, Online,\\nOctober 2020. Association for Computational Linguistics.\\ndoi: 10.18653/v1/2020.emnlp-demos.6.\\nWood, A., Najarian, K., and Kahrobaei, D. Homomorphic\\nencryption for machine learning in medicine and bioin-\\nformatics. ACM Computing Surveys (CSUR) , 53(4):1–35,\\n2020.\\nXu, L., Skoularidou, M., Cuesta-Infante, A., and Veera-\\nmachaneni, K. Modeling tabular data using conditional\\nGAN. In Proceedings of the 33rd International Confer-\\nence on Neural Information Processing Systems , number\\n659, pp. 7335–7345. Curran Associates Inc., Red Hook,\\nNY , USA, December 2019.\\nYang, Q., Liu, Y ., Chen, T., and Tong, Y . Federated machine\\nlearning: Concept and applications. ACM Transactions\\non Intelligent Systems and Technology (TIST) , 10(2):1–19,\\n2019.\\nYun, C., Bhojanapalli, S., Rawat, A. S., Reddi, S. J., and\\nKumar, S. Are transformers universal approximators\\nof sequence-to-sequence functions? arXiv preprint\\narXiv:1912.10077 , 2019.\\nZhao, Z., Kunar, A., Birke, R., and Chen, L. Y . Ctab-gan:\\nEffective table data synthesizing. In Asian Conference on\\nMachine Learning , pp. 97–112. PMLR, 2021.\\nZhao, Z., Kunar, A., Birke, R., and Chen, L. Y . Ctab-\\ngan+: Enhancing tabular data synthesis. arXiv preprint\\narXiv:2204.00401 , 2022.'),\n",
       " Document(metadata={'source': 'RealTabformer.pdf', 'page': 11}, page_content='REaLTabFormer: Generating Realistic Relational and Tabular Data using Transformers\\nA. Raw data processing\\nNumerical data Various methods have been proposed for\\nrepresenting numerical data as input to generative models\\nin the context of tabular data. The CTGAN and TV AE\\nmodels suggest the use of gaussian mixture models to en-\\ncode numerical values (Xu et al., 2019). On the other hand,\\nthe TabFormer model introduced quantization as a way to\\nencode numeric data (Padhi et al., 2021). However, these\\napproaches are lossy. As argued by Borisov et al. (2022),\\nthese lossy transformations may not be optimal.\\nIn our model, we adopt a fully text-based strategy in han-\\ndling numerical values. We apply a sequence of transforma-\\ntions that converts a column of numeric value into, possibly,\\nmulti-columnar data. We use the following transformation\\nof numerical columns. We also show the outcome of each\\ntransformation step on the sample numerical series below.\\nFor illustration, this example numerical-valued series\\n[1032.325345,10.291,-3.0]\\nis converted into\\n[“10”,“32”,“.3”,“3”]\\n[“00”,“10”,“.2”,“9”]\\n[“-0”,“03”,“.0”,“0”]\\n•We set a rounding resolution to normalize the size of\\nthe numerical values. For example, round to at most 2\\ndecimal places.\\n–[1032.33,10.29,-3.0]\\n• We then cast the values to string.\\n–[“1032.33”,“10.29”,“-3.0”]\\n•We identify the magnitude of the most signiﬁcant digit\\nof the largest value in the column by looking for the\\nlocation of the decimal point of the largest value. The\\nmagnitude of the most signiﬁcant digit for the largest\\nvalue in the example is 4.\\n–[“1032.33”,“10.29”,“-3.0”]\\n•We use the magnitude to left-align all the other values\\nin the data by padding them with leading zeros.\\n–[“1032.33”,“0010.29”,“00-3.0”]\\n•We then take the length of the longest string after this\\ntransformation and left-justify the data by padding ze-\\nros to the right of the values that are shorter than the\\nlongest string.\\n–[“1032.33”,“0010.29”,“00-3.00”]•Then, the negative sign for negative values is trans-\\nposed to the leftmost part of the string.\\n–[“1032.33”,“0010.29”,“-003.00”]\\n•Note that for integral values, we only perform the left\\nalignment by padding the values with leading zeros.\\nAfter this series of transformations, we tokenize the values\\ninto ﬁxed-length partitions. For the same example values,\\nsay we choose the partition size to be 2, we get the following\\ntokenized table.\\n[“10”,“32”,“.3”,“3”]\\n[“00”,“10”,“.2”,“9”]\\n[“-0”,“03”,“.0”,“0”]\\nThis transformation is done to mitigate the explosion of the\\nvocabulary if the numeric values are all distinct. We found\\nin our experiments that using single-character partitioning\\nworks best. We suppose that this effect is attributable to the\\ninherent regularization of generating an entire sequence of\\nnumbers one digit at a time.\\nDatetime data For date or time data types, we ﬁrst per-\\nform a transformation of the raw data into Unix timestamp\\nrepresentation. This representation is then treated as regular\\nnumeric data; hence, we apply the data processing discussed\\nfor numeric data types.\\nCategorical data Unique values in categorical columns\\nare treated as unique tokens in the vocabulary. No additional\\nprocessing is done.\\nMissing values No transformation is done for missing\\nvalues present in the data. We let the model learn the dis-\\ntribution of the missing values. This strategy gives us the\\nﬂexibility to let the model impute or generate missing values\\nduring the sampling process.\\nInput data aggregation As illustrated above, the trans-\\nformation of numerical data types expands the dataset by\\npartitioning the string version of the values. As such, we\\ncombine the processed columns into modiﬁed tabular data.\\nWe use this modiﬁed tabular data as input for our models.\\nEach unique value in the new columns in this data will be\\nmapped to a unique token in the vocabulary that is indepen-\\ndent of values in the other columns. This means that in the\\nillustrated numerical transformation shown above, the “1”\\nin the ﬁrst column will have a different token id than the “1”\\npresent in the third column.'),\n",
       " Document(metadata={'source': 'RealTabformer.pdf', 'page': 12}, page_content='REaLTabFormer: Generating Realistic Relational and Tabular Data using Transformers\\nTable 3. Summary of the datasets used in the experiments for non-relational tabular data.\\nAbbr Name # Train # Validation # Test # Num # Cat Task type\\nAB Abalone 2672 669 836 7 1 Regression\\nAD Adult ROC 26048 6513 16281 6 8 Binclass\\nBU Buddy 12053 3014 3767 4 5 Multiclass\\nCA California Housing 13209 3303 4128 8 0 Regression\\nDI Diabetes 491 123 154 8 0 Binclass\\nFB Facebook Comments V olume 157638 19722 19720 50 1 Regression\\nB. Datasets\\nB.1. Non-relational tabular data\\nWe used six real-world datasets to assess the performance of our proposed model for generating realistic and useful synthetic\\ntabular data. The datasets are diverse with respect to the types of variables—mix of numerical and categorical data types—as\\nwell as the number of variables in each dataset—ranging from 8 to 51 columns. The collection includes, Abalone (OpenML)2,\\nAdult (income estimation)3, Buddy (Kaggle)4, California Housing (real estate data)5, Diabetes (OpenML)6, and Facebook\\nComments7. Original source, copyright, and license information are available in the links in the footnote.\\nWe used the data splits by Kotelnikov et al. (2022) published in Tab-DDPM GitHub. Based on their pickled numpy data\\ndumps, we recreated the splits to create data frames that we can use for our experiments with REaLTabFormer and GReaT.\\nThe latter model expects contextual input from the column names.\\nWe also used the open-sourced optimized model parameters published in the above GitHub repo after reviewing the code,\\nand the correctness of the code relevant to producing the assets of interest has been conﬁrmed. We trained the TV AE,\\nCTABGAN+, and Tab-DDPM models from scratch using the parameters on each dataset.\\nB.2. Relational tabular data\\nTo test the REaLTabFormer in modeling relational datasets, we used two real-world data: the Rossmann store sales8dataset\\nand the Airbnb new user bookings9dataset.\\nWe created train and test splits. For the Rossmann dataset, we used 80% of the stores data and their associated sales records\\nfor our training data. We used the remaining stores as the test data. We also limit the data used in the experiments from\\n2015-06 onwards spanning 2 months of sales data per store. In the Airbnb dataset, we considered a random sample of\\n10,000 users for the experiment. We take 8,000 as part of our training data, and we assessed the metrics and plots using the\\n2,000 users in the test data. We also limit the users considered to those having at most 50 sessions in the data.\\nC. Reproducibility\\nWe used begreat==0.0.3 for the GReaT model. We used the Tab-DDPM GitHub repo version with this permanent\\nlink https://github.com/rotot0/tab-ddpm/tree/41f2415a378f1e8e8f4f5c3b8736521c0d47cf22. We used sdv==0.17.2\\nandsdmetrics==0.8.1 ; however, we ﬁxed a bug in the HyperTransformer implementation. We used\\ntransformers==4.25.1 andtorch==1.13.1 . We will open-source the REaLTabFormer package and experi-\\nments repository. We used Python version 3.9 .\\nWe ran our experiments on a standalone workstation with the following specs: 2x AMD EPYC 7H12 64-Core Processor, 2x\\nRTX 3090 GPU, and 1TB RAM running Ubuntu 20.04 LTS.\\n2Abalone (OpenML)\\n3Adult (income estimation)\\n4Buddy (Kaggle)\\n5California Housing (real estate data)\\n6Diabetes (OpenML)\\n7Facebook Comments\\n8Rossmann store sales\\n9Airbnb new user bookings'),\n",
       " Document(metadata={'source': 'RealTabformer.pdf', 'page': 13}, page_content='REaLTabFormer: Generating Realistic Relational and Tabular Data using Transformers\\nTable 4. Logistic detection measure for the generated parent, child, and merged tables by the Hierarchical Modeling Algorithm (HMA)\\nfrom SDV and the REaLTabFormer (RTF) models. This uses the logistic regression model as the detector.\\nDATASET TABLE SDV RTF\\nROSSMANNPARENT 78.67 ±6.79 92.75 ±4.28\\nCHILD 16.62 ±0.86 59.00 ±2.92\\nMERGED 12.00 ±0.73 50.69 ±2.41\\nAIRBNBPARENT 98.66 ±1.34 99.68 ±0.38\\nCHILD 0.00±0.00 26.33 ±0.78\\nMERGED 96.71 ±2.79 98.93 ±0.82\\nD. Other measures and results\\nWe also computed the logistic detection measure with the standard approach of using a logistic regression model. We ﬁnd\\nthat the logistic regression model appears to not provide reliable results Table 4. In particular, the scores returned by the\\nmodel are too high which is suspicious given that qualitative observation of the synthetic data hints at inaccuracies by both\\nmodels in producing perfect alignment with the original data. These spurious results may be due to the model’s limited\\ncapacity of learning the structure of the data. While techniques can be applied to help the model detect non-linearities better,\\nwe opted to report the results using the random forest as the base detector since it naturally is able to learn non-linearities\\nand appears to give reasonable results.\\nD.1. Joint plots\\nThe joint plot provides a qualitative assessment of the quality of the synthetic data generated by each model. We show in the\\nsequence of ﬁgures below the joint plots of two numerical variables in the datasets used.\\n0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6\\nShucked_weight0.00.10.20.30.40.50.60.7DiameterOriginal\\n0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6\\nShucked_weight0.00.10.20.30.40.50.60.7DiameterTVAE\\n0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6\\nShucked_weight0.00.10.20.30.40.50.60.7DiameterCTABGAN+\\n0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6\\nShucked_weight0.00.10.20.30.40.50.60.7DiameterT ab-DDPM\\n0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6\\nShucked_weight0.00.10.20.30.40.50.60.7DiameterGReaT\\n0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6\\nShucked_weight0.00.10.20.30.40.50.60.7DiameterREaLT abFormer\\nFigure 5. Joint plot of two numerical variables in the Abalone data compared across the samples generated by the different models.'),\n",
       " Document(metadata={'source': 'RealTabformer.pdf', 'page': 14}, page_content='REaLTabFormer: Generating Realistic Relational and Tabular Data using Transformers\\n10 20 30 40 50 60 70 80 90\\nage0246810121416education-numOriginal\\n10 20 30 40 50 60 70 80 90\\nage0246810121416education-numTVAE\\n10 20 30 40 50 60 70 80 90\\nage0246810121416education-numCTABGAN+\\n10 20 30 40 50 60 70 80 90\\nage0246810121416education-numT ab-DDPM\\n10 20 30 40 50 60 70 80 90\\nage0246810121416education-numGReaT\\n10 20 30 40 50 60 70 80 90\\nage0246810121416education-numREaLT abFormer\\nFigure 6. Joint plot of two numerical variables in the Adult data compared across the samples generated by the different models.\\n0.0 0.2 0.4 0.6 0.8 1.0\\nlength(m)01020304050height(cm)Original\\n0.0 0.2 0.4 0.6 0.8 1.0\\nlength(m)01020304050height(cm)TVAE\\n0.0 0.2 0.4 0.6 0.8 1.0\\nlength(m)01020304050height(cm)CTABGAN+\\n0.0 0.2 0.4 0.6 0.8 1.0\\nlength(m)01020304050height(cm)T ab-DDPM\\n0.0 0.2 0.4 0.6 0.8 1.0\\nlength(m)01020304050height(cm)GReaT\\n0.0 0.2 0.4 0.6 0.8 1.0\\nlength(m)01020304050height(cm)REaLT abFormer\\nFigure 7. Joint plot of two numerical variables in the Buddy data compared across the samples generated by the different models.'),\n",
       " Document(metadata={'source': 'RealTabformer.pdf', 'page': 15}, page_content='REaLTabFormer: Generating Realistic Relational and Tabular Data using Transformers\\n124\\n 122\\n 120\\n 118\\n 116\\n 114\\nLongitude3436384042LatitudeOriginal\\n124\\n 122\\n 120\\n 118\\n 116\\n 114\\nLongitude3436384042LatitudeTVAE\\n124\\n 122\\n 120\\n 118\\n 116\\n 114\\nLongitude3436384042LatitudeCTABGAN+\\n124\\n 122\\n 120\\n 118\\n 116\\n 114\\nLongitude3436384042LatitudeT ab-DDPM\\n124\\n 122\\n 120\\n 118\\n 116\\n 114\\nLongitude3436384042LatitudeGReaT\\n124\\n 122\\n 120\\n 118\\n 116\\n 114\\nLongitude3436384042LatitudeREaLT abFormer\\nFigure 8. Joint plot of two numerical variables in the California housing data compared across the samples generated by the different\\nmodels.\\n0 20 40 60 80 100 120\\nBloodPressure050100150200GlucoseOriginal\\n0 20 40 60 80 100 120\\nBloodPressure050100150200GlucoseTVAE\\n0 20 40 60 80 100 120\\nBloodPressure050100150200GlucoseCTABGAN+\\n0 20 40 60 80 100 120\\nBloodPressure050100150200GlucoseT ab-DDPM\\n0 20 40 60 80 100 120\\nBloodPressure050100150200GlucoseGReaT\\n0 20 40 60 80 100 120\\nBloodPressure050100150200GlucoseREaLT abFormer\\nFigure 9. Joint plot of two numerical variables in the Diabetes data compared across the samples generated by the different models.'),\n",
       " Document(metadata={'source': 'RealTabformer.pdf', 'page': 16}, page_content='REaLTabFormer: Generating Realistic Relational and Tabular Data using Transformers\\nD.2. Distance to closest record (DCR) distribution\\nWe present earlier the distance to closest record (DCR) distribution, Equation 2, as part of our proposed strategy to detect\\noverﬁtting in training the REaLTabFormer model. Here, we use the DCR distribution to visually assess whether the\\ngenerative models create exact copies of observations from the training data. We also show the DCR distribution of the real\\ntest data as a reference.\\n0.0 0.5 1.0 1.5\\nDCR0.000.250.500.751.001.251.50DensityOriginal\\n0.0 0.5 1.0 1.5\\nDCR0.000.250.500.751.001.251.50DensityTVAE\\n0.0 0.5 1.0 1.5\\nDCR0.000.250.500.751.001.251.50DensityCTABGAN+\\n0.0 0.5 1.0 1.5\\nDCR0.000.250.500.751.001.251.50DensityT ab-DDPM\\n0.0 0.5 1.0 1.5\\nDCR0.000.250.500.751.001.251.50DensityGReaT\\n0.0 0.5 1.0 1.5\\nDCR0.000.250.500.751.001.251.50DensityREaLT abFormer\\nFigure 10. Distance to closest record (DCR) distributions of the different models for the Abalone data.\\n0 1 2 3 4 5\\nDCR0.00.10.20.30.40.5DensityOriginal\\n0 1 2 3 4 5\\nDCR0.00.10.20.30.40.5DensityTVAE\\n0 1 2 3 4 5\\nDCR0.00.10.20.30.40.5DensityCTABGAN+\\n0 1 2 3 4 5\\nDCR0.00.10.20.30.40.5DensityT ab-DDPM\\n0 1 2 3 4 5\\nDCR0.00.10.20.30.40.5DensityGReaT\\n0 1 2 3 4 5\\nDCR0.00.10.20.30.40.5DensityREaLT abFormer\\nFigure 11. Distance to closest record (DCR) distributions of the different models for the Adult data.\\n0 1 2 3\\nDCR0.00.20.40.60.8DensityOriginal\\n0 1 2 3\\nDCR0.00.20.40.60.8DensityTVAE\\n0 1 2 3\\nDCR0.00.20.40.60.8DensityCTABGAN+\\n0 1 2 3\\nDCR0.00.20.40.60.8DensityT ab-DDPM\\n0 1 2 3\\nDCR0.00.20.40.60.8DensityGReaT\\n0 1 2 3\\nDCR0.00.20.40.60.8DensityREaLT abFormer\\nFigure 12. Distance to closest record (DCR) distributions of the different models for the Buddy data.\\n0.5 1.0 1.5\\nDCR0.000.250.500.751.001.251.50DensityOriginal\\n0.5 1.0 1.5\\nDCR0.000.250.500.751.001.251.50DensityTVAE\\n0.5 1.0 1.5\\nDCR0.000.250.500.751.001.251.50DensityCTABGAN+\\n0.5 1.0 1.5\\nDCR0.000.250.500.751.001.251.50DensityT ab-DDPM\\n0.5 1.0 1.5\\nDCR0.000.250.500.751.001.251.50DensityGReaT\\n0.5 1.0 1.5\\nDCR0.000.250.500.751.001.251.50DensityREaLT abFormer\\nFigure 13. Distance to closest record (DCR) distributions of the different models for the California housing data.\\n1 2 3 4\\nDCR0.00.20.40.60.8DensityOriginal\\n1 2 3 4\\nDCR0.00.20.40.60.8DensityTVAE\\n1 2 3 4\\nDCR0.00.20.40.60.8DensityCTABGAN+\\n1 2 3 4\\nDCR0.00.20.40.60.8DensityT ab-DDPM\\n1 2 3 4\\nDCR0.00.20.40.60.8DensityGReaT\\n1 2 3 4\\nDCR0.00.20.40.60.8DensityREaLT abFormer\\nFigure 14. Distance to closest record (DCR) distributions of the different models for the Diabetes data.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reading a PDF file\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"RealTabformer.pdf\")\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "loader = WebBaseLoader(web_paths=('https://lilianweng.github.io/posts/2023-06-23-agent/',),\n",
    "                       bs_kwargs=dict(parse_only = bs4.SoupStrainer(\n",
    "                           class_=(\"post-title\", \"post-content\",\"post-header\")\n",
    "                           ))\n",
    "                           )\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\\n\\nFig. 3. Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.\\n\\nFig. 4. Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)\\nChain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by explicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a collection of $D_h = \\\\{(x, y_i , r_i , z_i)\\\\}_{i=1}^n$, where $x$ is the prompt, each $y_i$ is a model completion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. Assume the feedback tuples are ranked by reward, $r_n \\\\geq r_{n-1} \\\\geq \\\\dots \\\\geq r_1$ The process is supervised fine-tuning where the data is a sequence in the form of $\\\\tau_h = (x, z_i, y_i, z_j, y_j, \\\\dots, z_n, y_n)$, where $\\\\leq i \\\\leq j \\\\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The model can optionally receive multiple rounds of instructions with human annotators at test time.\\nTo avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset. To avoid shortcutting and copying (because there are many common words in feedback sequences), they randomly mask 0% - 5% of past tokens during training.\\nThe training dataset in their experiments is a combination of WebGPT comparisons, summarization from human feedback and human preference dataset.\\n\\nFig. 5. After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. 2023)\\nThe idea of CoH is to present a history of sequentially improved outputs  in context and train the model to take on the trend to produce better outputs. Algorithm Distillation (AD; Laskin et al. 2023) applies the same idea to cross-episode trajectories in reinforcement learning tasks, where an algorithm is encapsulated in a long history-conditioned policy. Considering that an agent interacts with the environment many times and in each episode the agent gets a little better, AD concatenates this learning history and feeds that into the model. Hence we should expect the next predicted action to lead to better performance than previous trials. The goal is to learn the process of RL instead of training a task-specific policy itself.\\n\\nFig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.\\n\\nFig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.\\n\\nMaximum Inner Product Search (MIPS)#\\nThe external memory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding representation of information into a vector store database that can support fast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN)\\u200b algorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge speedup.\\nA couple common choices of ANN algorithms for fast MIPS:\\n\\nLSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items are mapped to the same buckets with high probability, where the number of buckets is much smaller than the number of inputs.\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random projection trees, a set of binary trees where each non-leaf node represents a hyperplane splitting the input space into half and each leaf stores one data point. Trees are built independently and at random, so to some extent, it mimics a hashing function. ANNOY search happens in all the trees to iteratively search through the half that is closest to the query and then aggregates the results. The idea is quite related to KD tree but a lot more scalable.\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks where most nodes can be reached by any other nodes within a small number of steps; e.g. “six degrees of separation” feature of social networks. HNSW builds hierarchical layers of these small-world graphs, where the bottom layers contain the actual data points. The layers in the middle create shortcuts to speed up search. When performing a search, HNSW starts from a random node in the top layer and navigates towards the target. When it can’t get any closer, it moves down to the next layer, until it reaches the bottom layer. Each move in the upper layers can potentially cover a large distance in the data space, and each move in the lower layers refines the search quality.\\nFAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional space, distances between nodes follow a Gaussian distribution and thus there should exist clustering of data points. FAISS applies vector quantization by partitioning the vector space into clusters and then refining the quantization within clusters. Search first looks for cluster candidates with coarse quantization and then further looks into each cluster with finer quantization.\\nScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector quantization. It quantizes a data point $x_i$ to $\\\\tilde{x}_i$ such that the inner product $\\\\langle q, x_i \\\\rangle$ is as similar to the original distance of $\\\\angle q, \\\\tilde{x}_i$ as possible, instead of picking the closet quantization centroid points.\\n\\n\\nFig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\nComponent Three: Tool Use#\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and utilize external objects to do things that go beyond our physical and cognitive limits. Equipping LLMs with external tools can significantly extend the model capabilities.\\n\\nFig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\nMRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of “expert” modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\\nThey did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the “External APIs” section of Prompt Engineering.\\nChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\nHuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.\\n\\nFig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:\\n\\nThe AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\n\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\\n\\n(4) Response generation: LLM receives the execution results and provides summarized results to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.\\nAPI-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar queries, smart home control, schedule management, health data management, account authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call and then uses the corresponding documentation to make a call.\\n\\nFig. 12. Pseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. 2023)\\nIn the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions include:\\n\\nWhether an API call is needed.\\nIdentify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\\nResponse based on the API results: the model can choose to refine and call again if results are not satisfied.\\n\\nThis benchmark evaluates the agent’s tool use capabilities at three levels:\\n\\nLevel-1 evaluates the ability to call the API. Given an API’s description, the model needs to determine whether to call a given API, call it correctly, and respond properly to API returns.\\nLevel-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the user’s requirement and learn how to use them by reading documentation.\\nLevel-3 assesses the ability to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.\\n\\nCase Studies#\\nScientific Discovery Agent#\\nChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\\nIt is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.\\n\\nOne interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results.\\nBoiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\nFor example, when requested to \"develop a novel anticancer drug\", the model came up with the following reasoning steps:\\n\\ninquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a scaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.\\n\\nThey also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n\\nPlanning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X\\'s plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\\n\\n\\n\\n\\nFig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes\\n\\nCommands:\\n1. Google Search: \"google\", args: \"input\": \"<search>\"\\n2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\\n3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\\n4. Message GPT Agent: \"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\\n5. List GPT Agents: \"list_agents\", args:\\n6. Delete GPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\\n7. Clone Repository: \"clone_repository\", args: \"repository_url\": \"<url>\", \"clone_path\": \"<directory>\"\\n8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n9. Read file: \"read_file\", args: \"file\": \"<file>\"\\n10. Append to file: \"append_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\\n12. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": \"<full_code_string>\"\\n14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\\n15. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\\n16. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\\n17. Generate Image: \"generate_image\", args: \"prompt\": \"<prompt>\"\\n18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\\n19. Do Nothing: \"do_nothing\", args:\\n20. Task Complete (Shutdown): \"task_complete\", args: \"reason\": \"<reason>\"\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\\n\\nYou should only respond in JSON format as described below\\nResponse Format:\\n{\\n    \"thoughts\": {\\n        \"text\": \"thought\",\\n        \"reasoning\": \"reasoning\",\\n        \"plan\": \"- short bulleted\\\\n- list that conveys\\\\n- long-term plan\",\\n        \"criticism\": \"constructive self-criticism\",\\n        \"speak\": \"thoughts summary to say to user\"\\n    },\\n    \"command\": {\\n        \"name\": \"command name\",\\n        \"args\": {\\n            \"arg name\": \"value\"\\n        }\\n    }\\n}\\nEnsure the response can be parsed by Python json.loads\\nGPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\\nHere are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Summary of areas that need clarification:\\\\n1. Specifics of the Super Mario game (e.g. level design, characters, gameplay mechanics)\\\\n2. Details about the MVC components (e.g. which components are in each file)\\\\n3. Keyboard control implementation (e.g. which keys to use, how to handle input)\\\\n\\\\nClarifying question:\\\\nCan you provide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\\n  }\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.\\nSystem message:\\n\\nYou will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code’s language, and CODE is the code:\\nFILENAME\\nCODE\\nYou will start with the “entrypoint” file, then go to the ones that are imported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency definition file.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create an appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very complex bits of logic.\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\npackage/project.\\nPython toolbelt preferences:\\n\\npytest\\ndataclasses\\n\\n\\nConversatin samples:\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\\\nInclude module dependency or package manager dependency definition file.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function definition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\\\npackage/project.\\\\n\\\\n\\\\nPython toolbelt preferences:\\\\n- pytest\\\\n- dataclasses\\\\n\"\\n  },\\n #  … same conversation as earlier, ended with \"Make your own assumptions and state them explicitly before starting\".\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Assumptions:\\\\n1. Model: The model will contain the game\\'s data, such as level information, character states, and enemy positions.\\\\n2. View: The view will handle the game\\'s visuals, including rendering the game objects, backgrounds, and updating the display.\\\\n3. Controller: The controller will manage user input, such as keyboard controls, and update the model accordingly.\\\\n\\\\nWith these assumptions in mind, is there any specific aspect of the keyboard control implementation you would like me to clarify?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"Please now remember the steps:\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nFirst lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. The code should be fully functional. Make sure that code in different files are compatible with each other.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\"\\n  }\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:\\n\\n\\nFinite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.\\n\\nOr\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: Dliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).\\n[5] Yao et al. “ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n[6] Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\n[8] Shinn & Labash. “Reflexion: an autonomous agent with dynamic memory and self-reflection” arXiv preprint arXiv:2303.11366 (2023).\\n[9] Laskin et al. “In-context Reinforcement Learning with Algorithm Distillation” ICLR 2023.\\n[10] Karpas et al. “MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.” arXiv preprint arXiv:2205.00445 (2022).\\n[11] Nakano et al. “Webgpt: Browser-assisted question-answering with human feedback.” arXiv preprint arXiv:2112.09332 (2021).\\n[12] Parisi et al. “TALM: Tool Augmented Language Models”\\n[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\\n[15] Li et al. “API-Bank: A Benchmark for Tool-Augmented LLMs” arXiv preprint arXiv:2304.08244 (2023).\\n[16] Shen et al. “HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace” arXiv preprint arXiv:2303.17580 (2023).\\n[17] Bran et al. “ChemCrow: Augmenting large-language models with chemistry tools.” arXiv preprint arXiv:2304.05376 (2023).\\n[18] Boiko et al. “Emergent autonomous scientific research capabilities of large language models.” arXiv preprint arXiv:2304.05332 (2023).\\n[19] Joon Sung Park, et al. “Generative Agents: Interactive Simulacra of Human Behavior.” arXiv preprint arXiv:2304.03442 (2023).\\n[20] AutoGPT. https://github.com/Significant-Gravitas/Auto-GPT\\n[21] GPT-Engineer. https://github.com/AntonOsika/gpt-engineer\\n')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Published': '2021-08-07', 'Title': 'Ranger21: a synergistic deep learning optimizer', 'Authors': 'Less Wright, Nestor Demeure', 'Summary': 'As optimizers are critical to the performances of neural networks, every year\\na large number of papers innovating on the subject are published. However,\\nwhile most of these publications provide incremental improvements to existing\\nalgorithms, they tend to be presented as new optimizers rather than composable\\nalgorithms. Thus, many worthwhile improvements are rarely seen out of their\\ninitial publication. Taking advantage of this untapped potential, we introduce\\nRanger21, a new optimizer which combines AdamW with eight components, carefully\\nselected after reviewing and testing ideas from the literature. We found that\\nthe resulting optimizer provides significantly improved validation accuracy and\\ntraining speed, smoother training curves, and is even able to train a ResNet50\\non ImageNet2012 without Batch Normalization layers. A problem on which AdamW\\nstays systematically stuck in a bad initial state.'}, page_content='RANGER21: A SYNERGISTIC DEEP LEARNING OPTIMIZER\\nA PREPRINT\\nLess Wright\\nAudereNow.org\\n1191 2nd Ave Ste 450\\nSeattle, WA 98101 USA\\nless@auderenow.org\\nNestor Demeure\\nNational Energy Research Scientific Computing Center,\\nLawrence Berkeley National Lab,\\n1 Cyclotron Road, Berkeley, California, 94720\\nndemeure@lbl.gov\\nAugust 10, 2021\\nABSTRACT\\nAs optimizers are critical to the performances of neural networks, every year a large number of\\npapers innovating on the subject are published. However, while most of these publications provide\\nincremental improvements to existing algorithms, they tend to be presented as new optimizers\\nrather than composable algorithms. Thus, many worthwhile improvements are rarely seen out of\\ntheir initial publication. Taking advantage of this untapped potential, we introduce Ranger21, a\\nnew optimizer which combines AdamW with eight components, carefully selected after reviewing\\nand testing ideas from the literature. We found that the resulting optimizer provides significantly\\nimproved validation accuracy and training speed, smoother training curves, and is even able to train a\\nResNet50 on ImageNet2012 without Batch Normalization layers. A problem on which AdamW stays\\nsystematically stuck in a bad initial state.\\nKeywords Deep-learning · Optimizer\\n1\\nIntroduction\\nOnce a task has been selected, an architecture designed and a dataset assembled, one needs to train a neural network in\\norder to make it performant as most neural network return random outputs in the absence of training. Thus, it has long\\nbeen understood that optimizers are a primordial component of deep-learning and that a good optimizer can drastically\\nimprove the performance of a given architecture.\\nCurrently Adam [1], which is short for Adaptive Moment Estimation, and in particular its variant AdamW [2] are\\namong the most commonly used optimizers in deep learning [3]. As such, many papers have proposed and tested new\\noptimization ideas that modify or enhance the core adaptive moment estimation optimization algorithm in various aspects\\nincluding forms of gradient normalization, improvement to the computation of the momentum, to the computation of\\nthe weight decay and of the step-size. We have found that these ideas, while typically presented as new optimizers, are\\noften composable. When tested and carefully combined, this can produce a synergistic result, where the combined\\nresult is stronger than the individual components alone. Ranger21 is our attempt at building such a synergistic optimizer\\nby selecting, testing and integrating eight distinct optimizer enhancements on top of AdamW.\\nOur work derives from Ranger [4], which was built in 2019 by combining two such algorithms (Rectified Adam [5]\\nand Lookahead [6]) into a single optimizer. As the name implies, Ranger21 synthesize our work to test and integrate\\nnew algorithms through 2021. When testing our optimizer on ImageNet2012 [7], as seen in section 4, we found out\\nthat it provided consistent improvements over AdamW. Training was smoother, achieved certain validation levels up to\\n3x faster, and most importantly, achieved a higher final validation accuracy. Furthermore, it was even able to train an\\narchitecture that AdamW completely fails at training (a ResNet50 [8] without its batch-normalization layers).\\nThis publication is split into five sections. Section one is this introduction, section two details the components that\\nmakes Ranger21 while section three gives the details of the full algorithm. Section four is dedicated to our experiments\\non the ImageNet2012 dataset and section five concludes with our results and potential improvements.\\narXiv:2106.13731v2  [cs.LG]  7 Aug 2021\\nA PREPRINT - AUGUST 10, 2021\\n2\\nComponents of the optimizer\\nThis section introduces the various components that make our optimizer and describes them as they are implemented in\\nRanger21.\\n2.1\\nAdam (adaptive moment estimation)\\nAdam [1] and in particular AdamW [2], which is detailed in algorithm 1, is the core of the Ranger21 optimizer. Adam\\nis short for Adaptive Moment Estimation and, as the name implies, it computes an adaptive step size for each parameter\\nby maintaining two exponential moving averages which track the first and second moment of the stochastic gradients.\\nBy using the sign of the stochastic gradient and a computed estimate of relative (or adaptive) variance derived from the\\ntwo moving averages, the magnitude and direction of the update are updated at each optimizer step.\\nAlgorithm 1 AdamW\\nRequire: f(θ): objective function\\nRequire: θ0: initial parameter vector\\nRequire: η: learning rate\\nRequire: λ: weight decay (default: 1e−4)\\nRequire: β1, β2 ∈[0, 1[: decay rates for Adam (default: 0.9, 0.999)\\nRequire: ϵ: epsilon for numerical stability (default: 1e−8)\\nRequire: tmax: number of iterations\\n1: m0, v0 ←0, 0\\n▷Initialization\\n2: for t ←1 to tmax do\\n3:\\ngt ←∇ft(θt−1)\\n▷Gradient\\n4:\\nmt ←β1 mt−1 + (1 −β1) gt\\n▷1st mom. estimate\\n5:\\nˆ︁mt ←mt/(1 −βt\\n1)\\n▷Bias correction\\n6:\\nvt ←β2 vt−1 + (1 −β2) g2\\nt\\n▷2nd mom. estimate\\n7:\\nˆ︁vt ←vt/(1 −βt\\n2)\\n▷Bias correction\\n8:\\nut ←ˆ︁mt/(√ˆ︁vt + ϵ)\\n▷Update vector\\n9:\\ndt ←λθt−1\\n▷Weight decay\\n10:\\nθt ←θt−1 −ηut −ηdt\\n▷Apply parameter update\\n11: end for\\n12: return θt\\nDue to Adam(W) being one of the most frequently used optimizers, [3], many publications offer various incremental\\nand innovative improvements on the algorithm, which is of particular interest to us as these individual enhancements\\nare often composable.\\n2.2\\nAdaptive Gradient Clipping\\nSporadic ’high loss’ mini-batches can destabilize stochastic gradient descent due to the back-propagation of excessively\\nlarge gradients. This is a common issue with smaller batch sizes and higher learning rates. To solve this problem one\\ncan use gradient-clipping, ensuring that the gradient stays below a given threshold (as seen in equation 1 where τ is the\\nthreshold and the norm is computed with a Frobenius norm).\\ngt =\\n{︄\\nτ\\ngt\\n∥gt∥\\nif ∥gt∥> τ,\\ngt\\notherwise.\\n(1)\\nTheoretical studies have shown that gradient clipping should help the optimizer traverse non-smooth regions of the loss\\nlandscape and accelerate convergence [9]. However, raw gradient clipping can affect the stability of the training, and\\nfinding a good threshold requires fine grained tuning based on the model depth, batch size and learning rate.\\nIn Ranger21, we use Adaptive Gradient Clipping [10]1 (not to be confused with another method by the same name\\npublished previously in [11]) in order to overcome these shortcomings. In Adaptive Gradient Clipping, the clipping\\nthreshold is dynamically updated to be proportional to the unit-wise ratio of gradient norms to parameter norms. This is\\n1We would like to thank Ali Kamer for pointing Adaptive Gradient Clipping to our attention.\\n2\\nA PREPRINT - AUGUST 10, 2021\\nshown in equation 2. ϵ is a constant, set to 10−3 by default, added to avoid freezing zero-initialized parameters, τ is set\\nto 10−2 by default and r denotes the fact that we are working on individual rows of a layer rather than a full layer.\\ngr\\nt =\\n{︄\\nτ max(∥θr\\nt ∥,ϵ)\\n∥gr\\nt ∥\\ngr\\nt\\nif\\n∥gr\\nt ∥\\nmax(∥θr\\nt ∥,ϵ) > τ,\\ngr\\nt\\notherwise.\\n(2)\\nWe found that Adaptive Gradient Clipping accelerates training while requiring only minimal tuning.\\n2.3\\nGradient Centralization\\nInspired by normalization techniques such as Batch Normalization [12], Gradient Centralization [13] suggests normal-\\nizing the gradient by subtracting its mean before using it inside an optimizer.\\nFor each layer that has more than one dimension, the mean of the gradient is computed along all but the first axis (i.e.\\nslice/matrix wise for convolution layers) and then subtracted from the gradient as shown in equation 3.\\ngcentralizedt = ∇ft(θt−1)−mean (∇ft(θt−1))\\n(3)\\nGradient Centralization imposes a constraint on the loss function and acts as a regularizer which, according to the\\nauthors, should smooth the optimization landscape. In practice, we observed improved generalization, a smoother\\ntraining curve and faster convergence when using it on networks that contains either fully connected layers and/or\\nconvolutional layers.\\n2.4\\nPositive-Negative Momentum\\nMomentum is used in modern deep learning optimizers to both smooth out the training noise and reduce the risk of\\nthe optimizer becoming stuck on saddle points and flat sections of the loss landscape. The classical, Adam-style,\\nformulation of momentum can be seen in lines 4 to 7 of algorithm 1.\\nAlgorithm 2 illustrates Positive-Negative Momentum (and in particular AdaPNM), a variant introduced in [14]. Notice\\nthat the update vector is normalized by\\n√︁\\n(1 + β0)2 + β2\\n0 such that changing the momentum hyper-parameter does not\\nrequire updating the learning rate.\\nAlgorithm 2 Positive-Negative Momentum\\nRequire: gt: gradient of the objective function\\nRequire: β0, β1, β2 ∈[0, 1[: decay rates for the momentums (default: 0.9, 0.9, 0.999)\\nRequire: ϵ: epsilon for numerical stability (default: 1e−8)\\n1: mt ←β2\\n1mt−2 + (1 −β2\\n1)gt\\n▷1st mom. estimate\\n2: ˆ︁mt ←((1 + β0)mt −β0mt−1)/(1 −βt\\n1)\\n▷Positive-negative momentum and bias correction\\n3: vt ←β2vt−1 + (1 −β2)g2\\nt\\n▷2nd mom. estimate\\n4: vmax ←max(vt, vmax)\\n▷2nd mom. maximum estimate\\n5: ˆ︁vt ←vmax/(1 −βt\\n2)\\n▷Bias correction\\n6: ut ←ˆ︁mt/(\\n√︁\\n(1 + β0)2 + β2\\n0(√ˆ︁vt + ϵ))\\n▷Update vector\\nThe key idea of Positive-Negative Momentum is to keep two sets of first moment estimates, one for odd iterations and\\none for even iterations. The moment applied during the optimization is an average of both sets, assigning a positive\\nweight to the current momentum estimation and a negative step to the previous one.\\nAccording to [14], this simulates the addition of a parameter-dependent, anisotropic, noise to the gradient which should\\nhelp escaping saddle points and pushing the optimizer toward flatter minima which are theorized to lead to better\\ngeneralization.\\nIn our tests, we were able to verify experimentally that Positive-Negative Momentum does indeed lead to improved\\nperformances on a variety of datasets, and integrates in a complementary fashion with the additional algorithms used in\\nRanger21.\\n3\\nA PREPRINT - AUGUST 10, 2021\\n2.5\\nNorm loss\\nIn AdamW style optimizers, weight decay is computed as in equation 4 (where η is the learning rate, λ the parameter\\nscaling the weight decay and θ the parameters that we are optimizing) and subtracted from the parameters during the\\nupdate step.\\ndAdamW = −ηλθ\\n(4)\\nNorm Loss [15] suggests using equation 5. Given a weight matrix co (which could be associated with a linear layer or\\na convolution layer for example), it takes into account ∥θco∥, the euclidian norm of the weight matrix, such that the\\nweight matrix is pushed toward a unit norm unlike traditional weight decay, which consistently pushes the weights\\ntoward zero.\\ndNormLossco = −ηλ\\n(︃\\n1 −\\n1\\n∥θco∥\\n)︃\\nθ\\n(5)\\nIn testing, we found that Norm Loss acts as a soft regularizer for the weight space and performs well across a large\\nvariety of hyper-parameters.\\n2.6\\nStable Weight Decay\\nAdamW-style weight decay uses the learning rate of the optimizer to weight the decay, as seen in equation 4. However,\\nthe actual step size is not only a function of the learning rate but also of ˆ︁vt, which represents the magnitude of the\\ngradient. Thus, the actual step size evolves during the iterations and a weight decay calibrated for the first iterations of\\ntraining will be too large for later iterations when ˆ︁vt goes down towards zero.\\nTo solve this problem, [16] introduces Stable Weight Decay which, as seen in equation 6 (where mean is the average\\nacross all coefficients of a layer), is a reweighting of AdamW-style weight decay to take the effective step size into\\naccount.\\ndstable = −\\nη\\n√︁\\nmean(ˆ︁vt)\\nλθ\\n(6)\\nIn our tests, we found that Stable Weight Decay gave us significant generalization improvements on vision tasks, in\\nkeeping with the authors affirmation that Stable Weight Decay allows adaptive optimizers to match and exceed SGD\\nresults on vision tasks. Furthermore, we observed that it can be integrated seamlessly with Norm Loss (giving us\\nequation 7) and that the benefits of both methods are additive, as they approach weight regularization from different\\nperspectives.\\ndstableloss = −\\nη\\n√︁\\nmean(ˆ︁vt)\\nλ\\n(︃\\n1 −\\n1\\n∥θco∥\\n)︃\\nθ\\n(7)\\n2.7\\nLinear learning rate warm-up\\nThe original Ranger optimizer was based on the Rectified Adam optimizer [5] which tries to fix some of the instability\\nproblems that Adam encounters due to large updates in the first iterations. However, [17] subsequently introduced a\\nmuch simpler alternative, relying only on a warm-up of the learning rate. As can be seen in equation 8, we follow\\ntheir suggestion and apply a linear warm-up of 2 · (1 −β2)−1 iterations to the learning rate (where β2 is the second\\nmomentum parameter) which is about 2000 iterations for default hyperparameter values. Since this schedule can\\nproduce a warm-up that is too long for shorter training runs, we additionally restrict it to the first twarmup iterations (by\\ndefault, 22% of tmax, the total iterations).\\nηt = min\\n(︃\\n1, max\\n(︃1 −β2\\n2\\n· t,\\nt\\ntwarmup\\n)︃)︃\\nη\\n(8)\\nIn our tests we found that this warm-up behave similarly to Rectified Adam, avoiding excessive step size during the first\\niterations, while being much simpler to implement.\\n4\\nA PREPRINT - AUGUST 10, 2021\\n2.8\\nExplore-Exploit learning rate schedule\\n[18] suggests an Explore-Exploit learning rate schedule: a phase of exploration, characterized by a constant high\\nlearning rate to find a flat minima, followed by a phase of exploitation where the learning rate is decreased linearly\\nto zero. The efficacy of this strategy has been confirmed experimentally in the Fastai leaderboard where the cosine\\nannealing (which is extremely similar to the explore-exploit learning rate) dominates [19, section 3]. As can be seen in\\nequation 9, given tmax iterations, we decrease the learning-rate linearly during the last twarmdown iteration (28% of the\\niterations by default).\\nηt = min\\n(︃\\n1, tmax −t\\ntwarmdown\\n)︃\\nη\\n(9)\\nBy combining the linear warm-up, a flat exploration phase, and a linear warm-down exploitation phase, we arrive at the\\nlearning-rate schedule given in equation 10 and illustrated in figure 1.\\nηt = min\\n(︃\\n1, max\\n(︃1 −β2\\n2\\n· t,\\nt\\ntwarmup\\n)︃\\n, tmax −t\\ntwarmdown\\n)︃\\nη\\n(10)\\n0.00000\\n0.00025\\n0.00050\\n0.00075\\n0.00100\\n0\\n2500\\n5000\\n7500\\n10000\\nIteration\\nLearning−rate\\nFigure 1: Evolution of the learning rate accross 10000 iterations with a base learning rate of 1e−3, a decay rate β2 of\\n0.999, a linear warm-up period of at most 22% of the iterations and a linear warm-down period of 28% of the iterations.\\n2.9\\nLookahead\\n[6] introduced Lookahead2, a technique consisting of keeping an exponential moving average of the weights that is\\nupdated and substituted to the current weights every klookahead steps (5 by default). To implement Lookahead, one can\\napply algorithm 3 at the end of the usual optimization step (where βlookahead is the momentum of the moving average,\\n0.5 by default).\\nRanger, our first optimizer which has now evolved into Ranger21, was built on a mix of the Rectified Adam optimizer\\nand Lookahead. While designing Ranger21, we found that Lookahead’s benefit subsists through the additions to the\\nalgorithm and that it gives us a net upward shift in the training validation curve on various datasets and a higher final\\nvalidation accuracy.\\n3\\nThe Ranger21 optimizer\\nAlgorithm 4 introduces Ranger213 which is the combination of all the aforementioned components.\\n2Interestingly and in keeping with the spirit of this paper, the authors remark in the abstract of their publication that Lookahead is\\northogonal to the majority of optimization techniques and can be used to improve most optimizers.\\n3It gets its name from the current year, 2021, and the fact that it evolved organically from the Ranger optimizer.\\n5\\nA PREPRINT - AUGUST 10, 2021\\nAlgorithm 3 Lookahead\\nRequire: t: current iteration number\\nRequire: klookahead: frequency of the update (default: 5)\\nRequire: βlookahead ∈[0, 1[: decay rate (default: 0.5)\\n1: l0 ←θ0\\n▷Initialization\\n2: ...\\n▷Usual parameter update\\n3: if t % klookahead == 0 then\\n4:\\nlt/k ←βlookaheadlt/k−1 + (1 −βlookahead)θt\\n▷Apply linear interpolation\\n5:\\nθt ←lt/k\\n▷Apply parameter update\\n6: end if\\nWhile the algorithm can appear daunting, it can be reduced to the eight previously mentioned ideas applied to the\\nAdam optimizer. Ranger21 combines these based on the findings that they are orthogonal, compatible with the Adam\\noptimizer and, in our tests, synergistic.\\nIt is interesting to note that while the algorithm adds a number of hyper-parameters, in our experience and across a\\nwide range of tasks, the default values for those additional parameters perform well without tuning. This is, in part,\\ndue to the fact that some algorithms we included (such as Stable Weight Decay) strive to reduce the sensitivity of the\\nalgorithm to it’s hyper-parameters.\\n4\\nExperiments\\nRather than using toy datasets, whose results often do not transfer to real world usage, we decided to focus on the\\nImageNet2012 dataset [7] to demonstrate the accuracy of our optimizer. To do so, we trained networks using both\\nRanger21 and AdamW for 60 epochs4 with a default learning rate of 3e−3.\\nWe used pictures of size 288x288 that were resized and either randomly cropped to 256x256 for the training set or\\ncenter cropped to 256x256 for the validation set. To further augment the training set, we also introduce random flip\\nalong the horizontal axis and random modifications in brightness, contrast and saturation (all of which are common data\\naugmentation techniques).\\nWe used Label Smoothing [20] (with a smoothing parameter of 0.1) as our loss function. It is commonly introduced to\\nenhance generalization by improving the model’s expected calibration error.\\n4.1\\nResNet50\\nFirst, we trained a very classical ResNet50 architecture [8]. At its highest point (the final iteration), Ranger21 reaches a\\nvalidation accuracy of 73.69% which is 2.61% higher than AdamW’s highest accuracy (71.08%, reached on epoch 52).\\nFurthermore, as can be seen in picture 2 (and in particular the loss section), Ranger21 leads not only to a consistently\\nbetter loss, but also to a much smoother training curve (which partially explains why the best result was reached on the\\nfinal iteration).\\nThe difference in convergence speed during training is well illustrated by the evolution of the loss during the first epochs\\nof training, as seen in figure 3. At 10 epochs Ranger21 reaches a result (0.03579) that will require AdamW more than\\n20 additional epochs to reach (it will only be equaled at epoch 35).\\n4.2\\nNormalizer-Free ResNet50\\nFor our second experiment, we trained a Normalizer-Free ResNet50. This architecture is identical to ResNet50 but\\nomits all the batch normalization layers which previously helped smooth the loss landscape.\\nAs can be seen in picture 4, AdamW is unable to converge for this architecture and keeps a constant, high (0.1),\\nloss5. By contrast, Ranger21 was able to train the network with slow (relative to a standard ResNet50) but steady loss\\nimprovements, and was still improving when we reached the 60 epoch cutoff point.\\n4Training on ImageNet2012 is often done in 300 epochs but it is computationally expensive and brings very little added value to\\nthis comparison.\\n5We tried this experiment five times with different random seeds to ensure that is was not a stroke of particularly bad luck. All\\nattempts failed similarly to the one shown.\\n6\\nA PREPRINT - AUGUST 10, 2021\\nAlgorithm 4 Ranger21\\nRequire: f(θ): objective function\\nRequire: θ0: initial parameter vector\\nRequire: η: learning rate\\nRequire: λ: weight decay (default: 1e−4)\\nRequire: β0, β1, β2, βlookahead ∈[0, 1[: decay rates (default: 0.9, 0.9, 0.999, 0.5)\\nRequire: ϵ, ϵclipping: epsilon for numerical stability (default: 1e−8, 1e−3)\\nRequire: τclipping: threshold for adaptive gradient clipping (default: 10−2 )\\nRequire: klookahead: frequency of the update (default: 5)\\nRequire: tmax: number of iterations\\nRequire: twarmup: number of learning rate warm-up iterations (default: 0.22 × tmax)\\nRequire: twarmdown: number of learning rate warm-down iterations (default: 0.28 × tmax)\\n1: m0, v0, vmax ←0, 0, 0\\n▷Initialization\\n2: l0 ←θ0\\n▷Lookahead initialization\\n3: for t ←1 to tmax do\\n4:\\ngt ←∇ft(θt−1)\\n▷Gradient\\n5:\\nfor r ∈rows(gt) do\\n6:\\nif\\n∥gr\\nt ∥\\nmax(∥θr\\nt ∥,ϵclipping) > τclipping then\\n7:\\ngr\\nt ←τclipping\\nmax(∥θr\\nt ∥,ϵclipping)\\n∥gr\\nt ∥\\ngr\\nt\\n▷Gradient clipping\\n8:\\nend if\\n9:\\nend for\\n10:\\ngt = gt −mean (gt)\\n▷Gradient centralization\\n11:\\nmt ←β2\\n1mt−2 + (1 −β2\\n1)gt\\n▷1st mom. estimate\\n12:\\nˆ︁mt ←((1 + β0)mt −β0mt−1)/(1 −βt\\n1)\\n▷Bias correction\\n13:\\nvt ←β2vt−1 + (1 −β2)g2\\nt\\n▷2nd mom. estimate\\n14:\\nvmax ←max(vt, vmax)\\n▷2nd mom. maximum estimate\\n15:\\nˆ︁vt ←vmax/(1 −βt\\n2)\\n▷Bias correction\\n16:\\nut ←ˆ︁mt/(\\n√︁\\n(1 + β0)2 + β2\\n0(√ˆ︁vt + ϵ))\\n▷Update vector\\n17:\\nηt = min\\n(︂\\n1, max\\n(︂\\n1−β2\\n2\\n· t,\\nt\\ntwarmup\\n)︂\\n,\\ntmax−t\\ntwarmdown\\n)︂\\nη\\n▷Learning rate scheduling\\n18:\\ndt =\\nηt\\n√\\nmean(ˆ︁vt)λ\\n(︂\\n1 −\\n1\\n∥θt−1∥\\n)︂\\nθt−1\\n▷Weight decay\\n19:\\nθt ←θt−1 −ηtut −ηtdt\\n▷Parameter update\\n20:\\nif t % klookahead == 0 then\\n21:\\nlt/k ←βlookaheadlt/k−1 + (1 −βlookahead)θt\\n22:\\nθt ←lt/k\\n▷Lookahead\\n23:\\nend if\\n24: end for\\n25: return θt\\nThis is particularly interesting because it illustrate a profound difference in capacities between Ranger21 and AdamW,\\nrather than an incremental improvement, despite Ranger21 deriving from AdamW.\\n5\\nConclusion\\nMany publications introduce incremental improvements to existing optimizers, but present them as new optimizers,\\nrather than as modules that could be combined. We believe that being aware of this modularity is important in order\\nto take full advantage of the research that is being done into deep learning optimization. We designed Ranger21\\nto highlight the benefits that can be gained from such a combination: testing and combining multiple independent\\nadvancements into a singular optimizer that is significantly better than its individual parts.\\nBy combining improvements in many sub-areas (such as momentum, loss and weight decay), we find that Ranger21 is\\nable to train models that other optimizers simply fail to train, like a Normalizer-Free Resnet50. More importantly, for\\na given model, Ranger21 is usually able to both accelerate the learning and achieve a net higher validation accuracy\\nwithout compromising generalization.\\n7\\nA PREPRINT - AUGUST 10, 2021\\n0.03\\n0.04\\n0.05\\n0.06\\n0.07\\n0\\n20\\n40\\n60\\nEpoch\\nLoss\\n0%\\n25%\\n50%\\n75%\\n100%\\n0\\n20\\n40\\n60\\nEpoch\\nAccuracy\\nDataset\\nTraining set\\nValidation set\\nOptimizer\\nAdam\\nRanger21\\nFigure 2: Evolution of the loss and accuracy, using either Adam or Ranger21, when training a ResNet50 convolutional\\nneural network on the ImageNet dataset. The y axis of the loss is displayed in logarithmic scale while the y axis of the\\naccuracy is in percent.\\n0.03\\n0.04\\n0.05\\n0.06\\n0.07\\n0\\n5\\n10\\n15\\n20\\nEpoch\\nLoss\\nOptimizer\\nAdam\\nRanger21\\nDataset\\nTraining Set\\nValidation Set\\nFigure 3: Plot of the loss for the first 20 iterations, using either Adam or Ranger21, when training a ResNet50\\nconvolutional neural network on the ImageNet dataset. The y axis is displayed in logarithmic scale.\\nWhile we have tested Ranger21 on several smaller datasets with even stronger out-performance, we felt that focusing on\\nImageNet2012 would be a good way to showcase the efficacy of our optimizer, as it is the gold standard in the domain\\nof image classification6. Thus, we hope that showing results on ImageNet2012 provides the reader with representative\\npicture of our work, as it may apply to real-world datasets.\\nHowever, every dataset and network architecture creates a unique loss landscape and our experiments are only a proxy\\nfor the behaviour of Ranger21 in the wild. Ranger21 is publicly available with ready to run PyTorch code7 and Flax\\ncode8 and we encourage users to try it for themselves and see if it brings real world improvement in their training9.\\nGoing forward, we are interested in trying to develop and integrate a finer-grained learning-rate scheduler to hopefully\\nboth improve performance and reduce the dependency on the default learning rate.\\nWe have also experimented with transformers [23] type of architecture, following their success in vision applications,\\nand would like to test whether some optimizer components are more beneficial to transformer than to other architectures.\\n6We also found that smaller datasets, such as MNIST [21] and CIFAR-10 [22], do not differentiate well between optimizers as all\\nend up performing roughly equivalently due to the simplicity of the task. Furthermore, testing on small scale datasets leads to results\\nthat are usually not representative of the results obtained when scaling to larger, real-world problems.\\n7Available on Github at the following url: https://github.com/lessw2020/Ranger21\\n8Available on Github at the following url: https://github.com/nestordemeure/flaxOptimizers\\n9We welcome feedback to further refine the components that make Ranger21 and keep it up to date with the state of the art.\\n8\\nA PREPRINT - AUGUST 10, 2021\\n0.05\\n0.06\\n0.07\\n0.08\\n0.10\\n0\\n20\\n40\\n60\\nEpoch\\nLoss\\n0%\\n25%\\n50%\\n75%\\n100%\\n0\\n20\\n40\\n60\\nEpoch\\nAccuracy\\nDataset\\nTraining set\\nValidation set\\nOptimizer\\nAdam\\nRanger21\\nFigure 4: Evolution of the loss and accuracy, using either Adam or Ranger21, when training a Normalizer-Free\\nResNet50 convolutional neural network on the ImageNet dataset. The y axis of the loss is displayed in logarithmic scale\\nwhile the y axis of the accuracy is in percents. Adam was stopped prematurely at 10 epochs as it was not converging.\\nFinally, a more general perspective would be the development of a fully modular optimizer architecture (possibly along\\nthe lines of Optax [24]) coupled with a meta-optimizer (such as a combinatorial bandit algorithm [25]) that would pick\\nand chose the components to build an optimizer tailor-made for a given task.\\nAcknowledgment\\nThis work was supported by the Director, Office of Science, Office of Advanced Scientific Computing Research, of the\\nU.S. Department of Energy under Contract No. DE-AC02-05CH11231\\nReferences\\n[1] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980,\\n2014.\\n[2] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101,\\n2017.\\n[3] Robin M Schmidt, Frank Schneider, and Philipp Hennig. Descending through a crowded valley–benchmarking\\ndeep learning optimizers. arXiv preprint arXiv:2007.01547, 2020.\\n[4] Less Wright. Ranger - a synergistic optimizer. https://github.com/lessw2020/Ranger-Deep-Learning-\\nOptimizer, 2019.\\n[5] Liyuan Liu, Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu, Jianfeng Gao, and Jiawei Han. On the\\nvariance of the adaptive learning rate and beyond. arXiv preprint arXiv:1908.03265, 2019.\\n[6] Michael Zhang, James Lucas, Jimmy Ba, and Geoffrey E Hinton. Lookahead optimizer: k steps forward, 1 step\\nback. In Advances in Neural Information Processing Systems, pages 9597–9608, 2019.\\n[7] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale hierarchical image database.\\nIn CVPR09, 2009.\\n[8] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In\\nProceedings of the IEEE conference on computer vision and pattern recognition, pages 770–778, 2016.\\n[9] Jingzhao Zhang, Tianxing He, Suvrit Sra, and Ali Jadbabaie. Why gradient clipping accelerates training: A\\ntheoretical justification for adaptivity. arXiv preprint arXiv:1905.11881, 2019.\\n[10] Andrew Brock, Soham De, Samuel L Smith, and Karen Simonyan. High-performance large-scale image recogni-\\ntion without normalization. arXiv preprint arXiv:2102.06171, 2021.\\n[11] Jeffrey M Ede and Richard Beanland. Adaptive learning rate clipping stabilizes learning. Machine Learning:\\nScience and Technology, 1(1):015011, 2020.\\n9\\nA PREPRINT - AUGUST 10, 2021\\n[12] Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal\\ncovariate shift. arXiv preprint arXiv:1502.03167, 2015.\\n[13] Hongwei Yong, Jianqiang Huang, Xiansheng Hua, and Lei Zhang. Gradient centralization: A new optimization\\ntechnique for deep neural networks. In European Conference on Computer Vision, pages 635–652. Springer, 2020.\\n[14] Zeke Xie, li Yuan, Zhanxing Zhu, and Masashi Sugiyama. Positive-negative momentum: Manipulating stochastic\\ngradient noise to improve generalization. arXiv preprint 2103.17182, 2021.\\n[15] Theodoros Georgiou, Sebastian Schmitt, Thomas B¨ack, Wei Chen, and Michael Lew. Norm loss: An efficient yet\\neffective regularization method for deep neural networks. arXiv preprint arXiv:2103.06583, 2021.\\n[16] Zeke Xie, Issei Sato, and Masashi Sugiyama. Stable weight decay regularization. arXiv preprint arXiv:2011.11152,\\n2020.\\n[17] Jerry Ma and Denis Yarats. On the adequacy of untuned warmup for adaptive optimization. arXiv preprint\\narXiv:1910.04209, 2019.\\n[18] Nikhil Iyer, V Thejas, Nipun Kwatra, Ramachandran Ramjee, and Muthian Sivathanu. Wide-minima density\\nhypothesis and the explore-exploit learning rate schedule. arXiv preprint arXiv:2003.03977, 2020.\\n[19] Less Wright. How we beat the fastai leaderboard score by +19.77%... a synergy of new deep learning techniques\\nfor your consideration. https://lessw.medium.com/how-we-beat-the-fastai-leaderboard-score-\\nby-19-77-a-cbb2338fab5c, 2019.\\n[20] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. Rethinking the inception\\narchitecture for computer vision. In Proceedings of the IEEE conference on computer vision and pattern\\nrecognition, pages 2818–2826, 2016.\\n[21] Y LeCun, C Cortes, and CJC Burgess. The mnist database of handwritten images, 2012.\\n[22] Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. Cifar-10 (canadian institute for advanced research). http:\\n// www. cs. toronto. edu/ kriz/ cifar. html , 5, 2010.\\n[23] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and\\nIllia Polosukhin. Attention is all you need. arXiv preprint arXiv:1706.03762, 2017.\\n[24] Matteo Hessel, David Budden, Fabio Viola, Mihaela Rosca, Eren Sezener, and Tom Hennigan. Optax: composable\\ngradient transformation and optimisation, in jax! http://github.com/deepmind/optax, 2020.\\n[25] Nicolo Cesa-Bianchi and G´abor Lugosi. Combinatorial bandits. Journal of Computer and System Sciences,\\n78(5):1404–1422, 2012.\\n10\\n')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader\n",
    "\n",
    "docs =  ArxivLoader(\"2106.13731\").load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
