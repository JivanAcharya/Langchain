{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model =\"Gemma2-9b-It\", groq_api_key= groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"It's nice to meet you, Jivan!  \\n\\nWhat kind of computer engineering are you interested in?  Hardware, software, networking, artificial intelligence?  I'm always eager to learn more about what people are working on in this field. \\n\\nTell me about yourself! What are you working on these days?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 21, 'total_tokens': 91, 'completion_time': 0.127272727, 'prompt_time': 0.000163629, 'queue_time': 0.012955331, 'total_time': 0.127436356}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-8447398f-f953-4897-a804-6578f14523e8-0', usage_metadata={'input_tokens': 21, 'output_tokens': 70, 'total_tokens': 91})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(\"Hello, I am Jivan and I am a Computer Engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You said your name is Jivan and you are a Computer Engineer!  \\n\\nIs there anything else you'd like to tell me about yourself or your work? üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 115, 'total_tokens': 154, 'completion_time': 0.070909091, 'prompt_time': 0.003554055, 'queue_time': 0.009726485, 'total_time': 0.074463146}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-f5ad2856-a175-47f3-a74f-632844a7275a-0', usage_metadata={'input_tokens': 115, 'output_tokens': 39, 'total_tokens': 154})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hello, I am Jivan and I am a Computer Engineer\"),\n",
    "        AIMessage(content=\"That's great! It's nice to meet another computer engineer. What area of computer engineering are you most interested in?\\n\\nI'm still under development, but I'm learning about many different things related to computer engineering.  Do you have any questions for me or any projects you're working on that you'd like to discuss?\\n\"),\n",
    "        HumanMessage(content =\"Hey what is my name and what do I do ?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import  ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import  RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hello, I am Jivan and I am a Computer Engineer\")],\n",
    "    config= config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's nice to meet you, Jivan! I'm Gemma, an AI assistant.  \\n\\nWhat are you working on these days? \\n\\nI'm always interested to hear about what people in Computer Engineering are up to.\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Jivan. üòä  I remember that from our first conversation! \\n\\nIs there anything else I can help you with?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 87, 'total_tokens': 118, 'completion_time': 0.056363636, 'prompt_time': 0.003278547, 'queue_time': 0.012547803, 'total_time': 0.059642183}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-4cd6ad60-18f1-49a2-908a-bccd74f248ab-0', usage_metadata={'input_tokens': 87, 'output_tokens': 31, 'total_tokens': 118})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey what is my name?\")],\n",
    "     config=config\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and don't know your name. If you'd like to tell me, I'm happy to know! üòä  \\n\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## changing the config --> session id\n",
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey what is my name?\")],\n",
    "     config=config1\n",
    "\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import  ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant. Answer all the question to the best of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Jivan, it's nice to meet you!  \\n\\nHow can I help you today? \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 31, 'total_tokens': 56, 'completion_time': 0.045454545, 'prompt_time': 0.000364869, 'queue_time': 0.01300692, 'total_time': 0.045819414}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-7532b77c-62f0-47a7-b4a1-0145dd06c411-0', usage_metadata={'input_tokens': 31, 'output_tokens': 25, 'total_tokens': 56})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hello, I am Jivan\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Jivan!  It's nice to meet you.\\n\\nWhat can I do for you today? üòä  \\n\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hello, I am Jivan\")],\n",
    "    config= config,\n",
    "\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding complexity to the prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant. Answer all the question to the best of your ability in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§ú‡§ø‡§µ‡§®! üëã \\n\\n‡§Æ‡§≤‡§æ‡§à ‡§§‡§™‡§æ‡§à‡§Ç‡§≤‡•á ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§∏‡•ã‡§ß‡•ç‡§®‡•Å‡§≠‡§Ø‡•ã ‡§≠‡§®‡•á ‡§Æ ‡§∏‡§¨‡•à‡§≠‡§®‡•ç‡§¶‡§æ ‡§∞‡§æ‡§Æ‡•ç‡§∞‡•ã ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•Å‡§®‡•ç‡§õ‡•§  \\n \\n\\n ‡§ï‡•á ‡§§‡§™‡§æ‡§à‡§Ç‡§≤‡§æ‡§à ‡§ï‡•á‡§π‡•Ä ‡§∏‡•ã‡§ß‡•ç‡§® ‡§ö‡§æ‡§π‡§®‡•Å‡§π‡•Å‡§®‡•ç‡§õ? üòä\\n\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response= chain.invoke({\"messages\":[HumanMessage(content=\"Hello, I am Jivan\")],\"language\":\"Nepali\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, \n",
    "                                                  get_session_history,\n",
    "                                                  input_messages_key=\"messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§ú‡§ø‡§µ‡§®!  üòä \\n\\n‡§Æ‡§≤‡§æ‡§à ‡§§‡§™‡§æ‡§à‡§Ç‡§ï‡•ã ‡§™‡•ç‡§∞‡§∂‡•ç‡§®‡§π‡§∞‡•Å‡§ï‡•ã ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡§ø‡§®‡•Å‡§Æ‡§æ ‡§ñ‡•Å‡§∂‡•Ä ‡§õ‡•Å‡•§ ‡§ï‡•á ‡§§‡§™‡§æ‡§à‡§Ç‡§≤‡§æ‡§à ‡§ï‡•á‡§π‡•Ä ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§õ?  \\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "response = with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"Hello, I am Jivan\")],\"language\":\"Nepali\"},\n",
    "    config= config\n",
    ")\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§Ü‡§™‡§ï‡•ã ‡§®‡§æ‡§Æ ‡§ú‡§ø‡§µ‡§® ‡§π‡•ã‡•§  \\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"What is my name?\")],\"language\":\"Nepali\"},\n",
    "    config= config\n",
    ")\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing  the conversation history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"Can you translate 'Hello' to Spanish?\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"'Hello' in Spanish is 'Hola'.\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What‚Äôs the fastest land animal?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The fastest land animal is the cheetah, capable of running up to 60-70 mph.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trim_messages acts as trimmer for the messages\n",
    "\n",
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens = 70,\n",
    "    strategy = \"last\",\n",
    "    token_counter = model,\n",
    "    include_system = True, \n",
    "    allow_partial = False,\n",
    "    start_on = \"human\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant\"),\n",
    "\n",
    "    HumanMessage(content=\"What‚Äôs the capital of France?\"),\n",
    "    AIMessage(content=\"The capital of France is Paris.\"),\n",
    "\n",
    "    HumanMessage(content=\"Can you recommend a good science fiction book?\"),\n",
    "    AIMessage(content=\"I recommend reading 'Dune' by Frank Herbert.\"),\n",
    "\n",
    "    HumanMessage(content=\"How do I boil an egg?\"),\n",
    "    AIMessage(content=\"To boil an egg, place it in a pot of water, bring it to a boil, then simmer for 9-12 minutes.\"),\n",
    "\n",
    "    HumanMessage(content=\"Tell me a joke.\"),\n",
    "    AIMessage(content=\"Why don't scientists trust atoms? Because they make up everything!\"),\n",
    "\n",
    "    HumanMessage(content=\"What‚Äôs the square root of 144?\"),\n",
    "    AIMessage(content=\"The square root of 144 is 12.\"),\n",
    "\n",
    "    HumanMessage(content=\"Can you translate 'Hello' to Spanish?\"),\n",
    "    AIMessage(content=\"'Hello' in Spanish is 'Hola'.\"),\n",
    "\n",
    "    HumanMessage(content=\"What‚Äôs the fastest land animal?\"),\n",
    "    AIMessage(content=\"The fastest land animal is the cheetah, capable of running up to 60-70 mph.\"),\n",
    "\n",
    "    ]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You haven't asked me to translate anything yet.  \\n\\nIs there anything you'd like me to translate? üòä \\n\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages = itemgetter(\"messages\") | trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "    \"messages\": messages + [HumanMessage(content=\"What language did I ask to Translate?\")],\n",
    "    \"language\": \"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I answered that the **cheetah** is the fastest land animal. üêÜ \\n\\n\\nDo you have any other questions? üòä\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "    \"messages\": messages + [HumanMessage(content=\"What animal did you answer ?\")],\n",
    "    \"language\": \"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrapping in message history\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(chain, \n",
    "                                                  get_session_history,\n",
    "                                                  input_messages_key=\"messages\")\n",
    "\n",
    "config = {\"configurable\":{\"session_id\":\"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cheetah! üêÜ  \\n\\n\\n\\nI said the cheetah is the fastest land animal.  \\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "    \"messages\": messages + [HumanMessage(content=\"What animal did you answer ?\")],\n",
    "    \"language\": \"English\"\n",
    "    },\n",
    "    config = config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
